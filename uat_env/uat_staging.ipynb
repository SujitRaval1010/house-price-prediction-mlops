{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3644d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================================\n",
    "# üöÄ UAT STAGING PROMOTION - CONFIG DRIVEN (FIXED)\n",
    "# =============================================================================\n",
    "# Purpose: Promote latest registered model to Staging alias\n",
    "# Now reads from pipeline_config.yml - No hardcoding!\n",
    "# Prerequisites: Run Model_Registration script first\n",
    "# =============================================================================\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import time\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ UAT STAGING PROMOTION (CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ LOAD PIPELINE CONFIGURATION\n",
    "# =============================================================================\n",
    "print(\"\\nüìã Loading pipeline configuration from pipeline_config.yml...\")\n",
    "\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract configuration\n",
    "    MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "    UC_CATALOG = pipeline_cfg[\"model\"][\"catalog\"]\n",
    "    UC_SCHEMA = pipeline_cfg[\"model\"][\"schema\"]\n",
    "    BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "    \n",
    "    # Auto-generate model name\n",
    "    MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.{BASE_NAME}_{MODEL_TYPE}_uc2\"\n",
    "    \n",
    "    STAGING_ALIAS = pipeline_cfg[\"aliases\"][\"staging\"]\n",
    "    METRIC_KEY = pipeline_cfg[\"metrics\"][\"primary_metric\"]\n",
    "    \n",
    "    TOL = 1e-6  # float tolerance for comparison\n",
    "    \n",
    "    print(f\"‚úÖ Configuration loaded successfully!\")\n",
    "    print(f\"\\nüìä Configuration Details:\")\n",
    "    print(f\"   Model Type: {MODEL_TYPE.upper()}\")\n",
    "    print(f\"   Model Name: {MODEL_NAME}\")\n",
    "    print(f\"   Staging Alias: @{STAGING_ALIAS}\")\n",
    "    print(f\"   Metric Key: {METRIC_KEY}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: pipeline_config.yml not found!\")\n",
    "    print(\"üí° Please create pipeline_config.yml in the same directory\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR loading configuration: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ INITIALIZE MLFLOW\n",
    "# =============================================================================\n",
    "try:\n",
    "    if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "        mlflow.set_registry_uri(\"databricks-uc\")\n",
    "        print(\"\\n‚úÖ Using Unity Catalog Registry\")\n",
    "    client = MlflowClient()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize MLflow client: {e}\")\n",
    "    raise e\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ HELPER: WAIT UNTIL MODEL VERSION IS READY\n",
    "# =============================================================================\n",
    "def wait_until_ready(client, model_name, version, timeout=300):\n",
    "    \"\"\"Wait for model version to become READY\"\"\"\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        mv = client.get_model_version(model_name, version)\n",
    "        status = mv.status\n",
    "        print(f\"‚è≥ Model v{version} status = {status}\")\n",
    "\n",
    "        if status == \"READY\":\n",
    "            return True\n",
    "        elif status == \"FAILED_REGISTRATION\":\n",
    "            print(\"‚ùå Model registration failed.\")\n",
    "            return False\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "    print(\"‚è∞ Timeout: Model is still not READY\")\n",
    "    return False\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ HELPER: GET METRIC FROM RUN\n",
    "# =============================================================================\n",
    "def get_metric_from_run(client, model_name, version, run_id):\n",
    "    \"\"\"Try to get metric from run or model version tags\"\"\"\n",
    "    metric_value = None\n",
    "    \n",
    "    # Method 1: Try to get from run metrics\n",
    "    try:\n",
    "        run = client.get_run(run_id)\n",
    "        metric_value = run.data.metrics.get(METRIC_KEY, None)\n",
    "        if metric_value is not None:\n",
    "            print(f\"  ‚úì Metric found in run metrics: {metric_value:.6f}\")\n",
    "            return metric_value\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Could not fetch run {run_id}: {e}\")\n",
    "    \n",
    "    # Method 2: Try to get from model version tags\n",
    "    try:\n",
    "        mv = client.get_model_version(model_name, version)\n",
    "        metric_tag = mv.tags.get(\"metric_rmse\", None)\n",
    "        if metric_tag:\n",
    "            metric_value = float(metric_tag)\n",
    "            print(f\"  ‚úì Metric found in model tags: {metric_value:.6f}\")\n",
    "            return metric_value\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Could not fetch metric from tags: {e}\")\n",
    "    \n",
    "    print(f\"  ‚ö† No metric found for version {version}\")\n",
    "    return None\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ STEP 1: FIND LATEST MODEL VERSION\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìã STEP 1: Finding Latest Model Version\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    model_versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "    if not model_versions:\n",
    "        print(f\"‚ùå No versions found for model: {MODEL_NAME}\")\n",
    "        print(\"\\nüí° Please run Model_Registration script first\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    latest_version = sorted(model_versions, key=lambda m: int(m.version), reverse=True)[0]\n",
    "    new_version = latest_version.version\n",
    "    new_run_id = latest_version.run_id\n",
    "\n",
    "    print(f\"\\n‚úÖ Latest Registered Model Version: v{new_version}\")\n",
    "    print(f\"   Run ID: {new_run_id}\")\n",
    "    print(f\"   Status: {latest_version.status}\")\n",
    "\n",
    "    # Get metric for new version\n",
    "    print(f\"\\nüîç Fetching metric for new version v{new_version}...\")\n",
    "    new_metric = get_metric_from_run(client, MODEL_NAME, new_version, new_run_id)\n",
    "\n",
    "    if new_metric is None:\n",
    "        print(f\"‚ùå ERROR: Could not find {METRIC_KEY} for new version v{new_version}\")\n",
    "        print(\"   This version cannot be evaluated. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"‚úÖ New Model {METRIC_KEY}: {new_metric:.6f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error finding latest version: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ STEP 2: FIND EXISTING STAGING MODEL\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìã STEP 2: Checking Current STAGING Model\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    staging_version = client.get_model_version_by_alias(MODEL_NAME, STAGING_ALIAS)\n",
    "    old_version = staging_version.version\n",
    "    old_run_id = staging_version.run_id\n",
    "\n",
    "    print(f\"\\nüìå Current STAGING Version: v{old_version}\")\n",
    "    print(f\"   Run ID: {old_run_id}\")\n",
    "    \n",
    "    # Get metric for old version\n",
    "    print(f\"\\nüîç Fetching metric for staging version v{old_version}...\")\n",
    "    old_metric = get_metric_from_run(client, MODEL_NAME, old_version, old_run_id)\n",
    "    \n",
    "    if old_metric is not None:\n",
    "        print(f\"üìå Current STAGING {METRIC_KEY}: {old_metric:.6f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è WARNING: Could not find {METRIC_KEY} for staging v{old_version}\")\n",
    "        print(\"   Will promote new model by default.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ÑπÔ∏è No current STAGING model found: {e}\")\n",
    "    print(\"   Will promote latest model to staging.\")\n",
    "    staging_version = None\n",
    "    old_metric = None\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ STEP 3: COMPARE METRICS (LOWER RMSE = BETTER)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìã STEP 3: Metric Comparison\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "promote = False\n",
    "promotion_reason = \"\"\n",
    "\n",
    "if staging_version is None:\n",
    "    promote = True\n",
    "    promotion_reason = \"No existing staging model\"\n",
    "    print(f\"\\nüü¢ DECISION: PROMOTE\")\n",
    "    print(f\"   Reason: {promotion_reason}\")\n",
    "    \n",
    "elif old_metric is None:\n",
    "    promote = True\n",
    "    promotion_reason = \"Staging model has no metric (old version)\"\n",
    "    print(f\"\\nüü¢ DECISION: PROMOTE\")\n",
    "    print(f\"   Reason: {promotion_reason}\")\n",
    "    \n",
    "else:\n",
    "    # Both metrics exist - compare them\n",
    "    print(f\"\\nüìä Metric Comparison:\")\n",
    "    print(f\"   New Model (v{new_version}):     {METRIC_KEY} = {new_metric:.6f}\")\n",
    "    print(f\"   Staging Model (v{old_version}): {METRIC_KEY} = {old_metric:.6f}\")\n",
    "    print(f\"   Improvement:                     {old_metric - new_metric:.6f}\")\n",
    "    \n",
    "    if new_metric < old_metric - TOL:\n",
    "        promote = True\n",
    "        improvement_pct = ((old_metric - new_metric) / old_metric) * 100\n",
    "        promotion_reason = f\"New model is better (improvement: {improvement_pct:.2f}%)\"\n",
    "        print(f\"\\nüü¢ DECISION: PROMOTE\")\n",
    "        print(f\"   Reason: {promotion_reason}\")\n",
    "        \n",
    "    elif abs(new_metric - old_metric) <= TOL:\n",
    "        print(f\"\\nüü° DECISION: NO PROMOTION\")\n",
    "        print(f\"   Reason: New model performance is same as staging (within tolerance)\")\n",
    "        print(f\"   Keeping existing staging version v{old_version}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚õî DECISION: NO PROMOTION\")\n",
    "        print(f\"   Reason: New model is WORSE than staging\")\n",
    "        print(f\"   Degradation: {(new_metric - old_metric):.6f}\")\n",
    "        print(f\"   Keeping existing staging version v{old_version}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ STEP 4: PROMOTE USING ALIAS\n",
    "# =============================================================================\n",
    "if promote:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Promoting Model to STAGING\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\n‚è≥ Waiting for model v{new_version} to become READY...\")\n",
    "    if wait_until_ready(client, MODEL_NAME, new_version):\n",
    "        \n",
    "        try:\n",
    "            # Set the alias\n",
    "            client.set_registered_model_alias(\n",
    "                name=MODEL_NAME,\n",
    "                alias=STAGING_ALIAS,\n",
    "                version=new_version\n",
    "            )\n",
    "\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(\"‚úÖ‚úÖ PROMOTION SUCCESSFUL ‚úÖ‚úÖ\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"   Model: {MODEL_NAME}\")\n",
    "            print(f\"   Model Type: {MODEL_TYPE.upper()}\")\n",
    "            print(f\"   New STAGING Version: v{new_version}\")\n",
    "            print(f\"   {METRIC_KEY}: {new_metric:.6f}\")\n",
    "            print(f\"   Reason: {promotion_reason}\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "            \n",
    "            # Save for workflow\n",
    "            try:\n",
    "                dbutils.jobs.taskValues.set(key=\"staging_version\", value=new_version)\n",
    "                dbutils.jobs.taskValues.set(key=\"staging_metric\", value=new_metric)\n",
    "                print(\"‚úÖ Task values saved for workflow\")\n",
    "            except:\n",
    "                print(\"‚ÑπÔ∏è Not running in workflow - skipping task values\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Failed to set alias: {e}\")\n",
    "            traceback.print_exc()\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        print(\"\\n‚ùå Promotion failed: Model did not become READY in time.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ STAGING UNCHANGED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    if staging_version:\n",
    "        print(f\"   Current STAGING Version: v{old_version}\")\n",
    "        if old_metric:\n",
    "            print(f\"   {METRIC_KEY}: {old_metric:.6f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Save for workflow even if no promotion\n",
    "    try:\n",
    "        dbutils.jobs.taskValues.set(key=\"staging_version\", value=old_version if staging_version else None)\n",
    "        dbutils.jobs.taskValues.set(key=\"staging_metric\", value=old_metric if old_metric else None)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\nüìå Next Step:\")\n",
    "print(\"   Run 05_uat_inference.py to validate the staging model\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
