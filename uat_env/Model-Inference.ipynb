{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"UAT MODEL INFERENCE - STAGING VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "UC_CATALOG_NAME = \"workspace\"\n",
    "UC_SCHEMA_NAME = \"ml\"\n",
    "MODEL_NAME = f\"{UC_CATALOG_NAME}.{UC_SCHEMA_NAME}.house_price_model_uc\"\n",
    "\n",
    "DATA_CATALOG_NAME = \"workspace\"\n",
    "DATA_SCHEMA_NAME = \"default\"\n",
    "TABLE_NAME = \"house_price_delta\"\n",
    "FULL_TABLE_NAME = f\"{DATA_CATALOG_NAME}.{DATA_SCHEMA_NAME}.{TABLE_NAME}\"\n",
    "\n",
    "EXPERIMENT_NAME = \"/Shared/House_Price_Prediction_Delta_RF\"\n",
    "\n",
    "FEATURE_COLUMNS = ['sq_feet', 'num_bedrooms', 'num_bathrooms', 'year_built', 'location_score']\n",
    "LABEL_COLUMN = 'price'\n",
    "\n",
    "MAX_ACCEPTABLE_MAPE = 15.0\n",
    "MIN_ACCEPTABLE_R2 = 0.75\n",
    "\n",
    "# =============================================================================\n",
    "# SPARK SESSION\n",
    "# =============================================================================\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"UAT_ModelInference\").getOrCreate()\n",
    "    print(\"Spark session initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Spark: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# GET MODEL ALIAS FROM WIDGET\n",
    "# =============================================================================\n",
    "try:\n",
    "    model_alias = dbutils.widgets.get(\"alias\")\n",
    "    print(f\"Model Alias from widget: {model_alias}\")\n",
    "except:\n",
    "    model_alias = \"Staging\"\n",
    "    print(f\"Widget not found, using default: {model_alias}\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD MODEL\n",
    "# =============================================================================\n",
    "print(f\"\\nLoading model for UAT validation...\")\n",
    "print(f\"Target Alias: {model_alias}\")\n",
    "\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if not experiment:\n",
    "        raise Exception(f\"Experiment '{EXPERIMENT_NAME}' not found\")\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=\"status = 'FINISHED'\",\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "\n",
    "    if not runs:\n",
    "        raise Exception(\"No successful runs found. Please train a model first.\")\n",
    "\n",
    "    latest_run = runs[0]\n",
    "    run_id = latest_run.info.run_id\n",
    "\n",
    "    print(f\"\\nModel Details:\\n  Run ID: {run_id}\\n  Run Name: {latest_run.info.run_name}\")\n",
    "\n",
    "    print(\"\\n  Training Parameters:\")\n",
    "    for k, v in latest_run.data.params.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    print(\"\\n  Training Metrics:\")\n",
    "    training_metrics = {k: v for k, v in latest_run.data.metrics.items()}\n",
    "    for k, v in training_metrics.items():\n",
    "        print(f\"    {k}: {v:.4f}\")\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/sklearn_rf_model\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(\"\\nModel loaded successfully for UAT validation\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading model: {e}\")\n",
    "    import traceback; traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD TEST DATA\n",
    "# =============================================================================\n",
    "print(f\"\\nLoading test data from: {FULL_TABLE_NAME}\")\n",
    "\n",
    "try:\n",
    "    spark_df = spark.read.format(\"delta\").table(FULL_TABLE_NAME)\n",
    "    print(f\"Data loaded: {spark_df.count()} rows\")\n",
    "\n",
    "    available_cols = spark_df.columns\n",
    "    missing_cols = [c for c in FEATURE_COLUMNS + [LABEL_COLUMN] if c not in available_cols]\n",
    "    if missing_cols:\n",
    "        raise Exception(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    pandas_df = spark_df.select(*FEATURE_COLUMNS, LABEL_COLUMN).toPandas()\n",
    "    print(f\"Converted to Pandas: {pandas_df.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading data: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\\nRUNNING INFERENCE ON UAT DATA\\n{'='*70}\")\n",
    "\n",
    "try:\n",
    "    X_test = pandas_df[FEATURE_COLUMNS]\n",
    "    y_actual = pandas_df[LABEL_COLUMN]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    pandas_df['predicted_price'] = y_pred\n",
    "    pandas_df['prediction_error'] = y_actual - y_pred\n",
    "    pandas_df['absolute_error'] = abs(pandas_df['prediction_error'])\n",
    "    pandas_df['percentage_error'] = (pandas_df['absolute_error'] / y_actual) * 100\n",
    "    print(f\"\\nPredictions completed: {len(y_pred)} samples\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during prediction: {e}\")\n",
    "    import traceback; traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# METRIC CALCULATION\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\\nUAT VALIDATION METRICS\\n{'='*70}\")\n",
    "\n",
    "try:\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    mape = (abs(y_actual - y_pred) / y_actual * 100).mean()\n",
    "\n",
    "    # Handle NaN/Inf safely\n",
    "    if np.isnan(rmse) or np.isinf(rmse): rmse = 999999.99\n",
    "    if np.isnan(r2): r2 = 0.0\n",
    "    if np.isnan(mape) or np.isinf(mape): mape = 100.0\n",
    "\n",
    "    print(f\"\\nRegression Metrics:\\n  MAE: ${mae:,.2f}\\n  RMSE: ${rmse:,.2f}\\n  R¬≤: {r2:.4f}\\n  MAPE: {mape:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError calculating metrics: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# LOG METRICS TO MLFLOW  ‚úÖ (Fix)\n",
    "# =============================================================================\n",
    "print(f\"\\nLogging UAT metrics to MLflow for promotion tracking...\")\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.log_metric(\"uat_mae\", mae)\n",
    "        mlflow.log_metric(\"uat_rmse\", rmse)\n",
    "        mlflow.log_metric(\"uat_r2_score\", r2)\n",
    "        mlflow.log_metric(\"uat_mape\", mape)\n",
    "\n",
    "        # For Promotion Script compatibility\n",
    "        mlflow.log_metric(\"test_rmse\", rmse)\n",
    "        mlflow.log_metric(\"test_r2_score\", r2)\n",
    "        mlflow.log_metric(\"best_cv_rmse\", training_metrics.get(\"best_cv_rmse\", 0.0))\n",
    "\n",
    "    print(\"‚úÖ UAT metrics successfully logged to MLflow.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not log UAT metrics to MLflow: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION PASS/FAIL\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\\nUAT VALIDATION RESULTS\\n{'='*70}\")\n",
    "\n",
    "validation_passed = True\n",
    "results = []\n",
    "\n",
    "if mape <= MAX_ACCEPTABLE_MAPE:\n",
    "    results.append(f\"PASS: MAPE {mape:.2f}% <= {MAX_ACCEPTABLE_MAPE}%\")\n",
    "else:\n",
    "    results.append(f\"FAIL: MAPE {mape:.2f}% > {MAX_ACCEPTABLE_MAPE}%\")\n",
    "    validation_passed = False\n",
    "\n",
    "if r2 >= MIN_ACCEPTABLE_R2:\n",
    "    results.append(f\"PASS: R¬≤ {r2:.4f} >= {MIN_ACCEPTABLE_R2}\")\n",
    "else:\n",
    "    results.append(f\"FAIL: R¬≤ {r2:.4f} < {MIN_ACCEPTABLE_R2}\")\n",
    "    validation_passed = False\n",
    "\n",
    "for res in results:\n",
    "    print(\"  \" + res)\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"\\n‚úÖ UAT VALIDATION: PASSED ‚Äì Model ready for Production.\")\n",
    "else:\n",
    "    print(\"\\nüö´ UAT VALIDATION: FAILED ‚Äì Retrain with better parameters/data.\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS (UNCHANGED LOGIC)\n",
    "# =============================================================================\n",
    "# Your existing save logic remains unchanged here.\n",
    "# [ ... Keep your fingerprint and delta save logic block as it is ... ]\n",
    "\n",
    "# =============================================================================\n",
    "# EXIT CODE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\\nUAT INFERENCE COMPLETE\\n{'='*70}\")\n",
    "if not validation_passed:\n",
    "    try:\n",
    "        dbutils.notebook.exit(\"FAILED\")\n",
    "    except:\n",
    "        raise Exception(\"UAT Validation Failed: Model does not meet quality thresholds\")\n",
    "else:\n",
    "    try:\n",
    "        dbutils.notebook.exit(\"PASSED\")\n",
    "    except:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
