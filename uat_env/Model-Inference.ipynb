{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"UAT MODEL INFERENCE - STAGING VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "UC_CATALOG_NAME = \"workspace\"\n",
    "UC_SCHEMA_NAME = \"ml\"\n",
    "MODEL_NAME = f\"{UC_CATALOG_NAME}.{UC_SCHEMA_NAME}.house_price_model_uc\"\n",
    "\n",
    "DATA_CATALOG_NAME = \"workspace\"\n",
    "DATA_SCHEMA_NAME = \"default\"\n",
    "TABLE_NAME = \"house_price_delta\"\n",
    "FULL_TABLE_NAME = f\"{DATA_CATALOG_NAME}.{DATA_SCHEMA_NAME}.{TABLE_NAME}\"\n",
    "\n",
    "EXPERIMENT_NAME = \"/Shared/House_Price_Prediction_Delta_RF\"\n",
    "\n",
    "FEATURE_COLUMNS = ['sq_feet', 'num_bedrooms', 'num_bathrooms', 'year_built', 'location_score']\n",
    "LABEL_COLUMN = 'price'\n",
    "\n",
    "MAX_ACCEPTABLE_MAPE = 15.0\n",
    "MIN_ACCEPTABLE_R2 = 0.75\n",
    "\n",
    "STAGING_ALIAS = \"staging\"\n",
    "\n",
    "# =============================================================================\n",
    "# SPARK SESSION\n",
    "# =============================================================================\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"UAT_ModelInference\").getOrCreate()\n",
    "    print(\"✓ Spark session initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing Spark: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# MLFLOW SETUP\n",
    "# =============================================================================\n",
    "try:\n",
    "    if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "        mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    \n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    client = MlflowClient()\n",
    "    print(\"✓ MLflow configured\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error setting up MLflow: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# GET MODEL ALIAS FROM WIDGET\n",
    "# =============================================================================\n",
    "try:\n",
    "    model_alias = dbutils.widgets.get(\"alias\")\n",
    "    print(f\"Model Alias from widget: {model_alias}\")\n",
    "except:\n",
    "    model_alias = STAGING_ALIAS\n",
    "    print(f\"Widget not found, using default: {model_alias}\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD LATEST TRAINED MODEL & GET TRAINING METRICS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LOADING MODEL FOR UAT VALIDATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if not experiment:\n",
    "        raise Exception(f\"Experiment '{EXPERIMENT_NAME}' not found\")\n",
    "\n",
    "    # Get latest successful training run\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=\"status = 'FINISHED'\",\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "\n",
    "    if not runs:\n",
    "        raise Exception(\"No successful runs found. Please train a model first.\")\n",
    "\n",
    "    training_run = runs[0]\n",
    "    training_run_id = training_run.info.run_id\n",
    "\n",
    "    print(f\"\\n✓ Found Latest Training Run:\")\n",
    "    print(f\"  Run ID: {training_run_id}\")\n",
    "    print(f\"  Run Name: {training_run.info.run_name}\")\n",
    "\n",
    "    # Get training metrics\n",
    "    training_metrics = training_run.data.metrics\n",
    "    training_params = training_run.data.params\n",
    "\n",
    "    print(\"\\n  Training Parameters:\")\n",
    "    for k, v in training_params.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    print(\"\\n  Training Metrics:\")\n",
    "    for k, v in training_metrics.items():\n",
    "        print(f\"    {k}: {v:.4f}\")\n",
    "\n",
    "    # Load the model\n",
    "    model_uri = f\"runs:/{training_run_id}/sklearn_rf_model\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(\"\\n✓ Model loaded successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD TEST DATA\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LOADING TEST DATA\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Table: {FULL_TABLE_NAME}\")\n",
    "\n",
    "try:\n",
    "    spark_df = spark.read.format(\"delta\").table(FULL_TABLE_NAME)\n",
    "    total_rows = spark_df.count()\n",
    "    print(f\"✓ Data loaded: {total_rows} rows\")\n",
    "\n",
    "    available_cols = spark_df.columns\n",
    "    missing_cols = [c for c in FEATURE_COLUMNS + [LABEL_COLUMN] if c not in available_cols]\n",
    "    if missing_cols:\n",
    "        raise Exception(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    pandas_df = spark_df.select(*FEATURE_COLUMNS, LABEL_COLUMN).toPandas()\n",
    "    print(f\"✓ Converted to Pandas: {pandas_df.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading data: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# RUN PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RUNNING UAT INFERENCE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    X_test = pandas_df[FEATURE_COLUMNS]\n",
    "    y_actual = pandas_df[LABEL_COLUMN]\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    pandas_df['predicted_price'] = y_pred\n",
    "    pandas_df['prediction_error'] = y_actual - y_pred\n",
    "    pandas_df['absolute_error'] = abs(pandas_df['prediction_error'])\n",
    "    pandas_df['percentage_error'] = (pandas_df['absolute_error'] / y_actual) * 100\n",
    "    \n",
    "    print(f\"✓ Predictions completed: {len(y_pred)} samples\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during prediction: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# CALCULATE UAT METRICS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"UAT VALIDATION METRICS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    mape = (abs(y_actual - y_pred) / y_actual * 100).mean()\n",
    "\n",
    "    # Handle NaN/Inf safely\n",
    "    if np.isnan(rmse) or np.isinf(rmse): \n",
    "        rmse = 999999.99\n",
    "    if np.isnan(r2): \n",
    "        r2 = 0.0\n",
    "    if np.isnan(mape) or np.isinf(mape): \n",
    "        mape = 100.0\n",
    "\n",
    "    print(f\"\\nUAT Metrics:\")\n",
    "    print(f\"  MAE: ${mae:,.2f}\")\n",
    "    print(f\"  RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error calculating metrics: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# ✅ CREATE NEW UAT RUN AND LOG METRICS (FIXED!)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LOGGING UAT METRICS TO MLFLOW\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    # ✅ Create a NEW run for UAT validation (don't reuse training run)\n",
    "    with mlflow.start_run(run_name=f\"UAT_Validation_{model_alias}\") as uat_run:\n",
    "        uat_run_id = uat_run.info.run_id\n",
    "        \n",
    "        # Log UAT metrics\n",
    "        mlflow.log_metric(\"uat_mae\", mae)\n",
    "        mlflow.log_metric(\"uat_rmse\", rmse)\n",
    "        mlflow.log_metric(\"uat_r2_score\", r2)\n",
    "        mlflow.log_metric(\"uat_mape\", mape)\n",
    "        \n",
    "        # ✅ CRITICAL: Log metrics that promotion script expects\n",
    "        mlflow.log_metric(\"test_rmse\", rmse)\n",
    "        mlflow.log_metric(\"test_r2_score\", r2)\n",
    "        \n",
    "        # Log training metrics for reference\n",
    "        best_cv_rmse = training_metrics.get(\"best_cv_rmse\", 0.0)\n",
    "        mlflow.log_metric(\"best_cv_rmse\", best_cv_rmse)\n",
    "        \n",
    "        # Log training params for traceability\n",
    "        for param_key, param_value in training_params.items():\n",
    "            mlflow.log_param(param_key, param_value)\n",
    "        \n",
    "        # Link to original training run\n",
    "        mlflow.set_tag(\"training_run_id\", training_run_id)\n",
    "        mlflow.set_tag(\"validation_stage\", \"UAT\")\n",
    "        mlflow.set_tag(\"model_alias\", model_alias)\n",
    "        \n",
    "        print(f\"\\n✓ UAT Run Created:\")\n",
    "        print(f\"  UAT Run ID: {uat_run_id}\")\n",
    "        print(f\"  Linked Training Run: {training_run_id}\")\n",
    "    \n",
    "    print(\"✓ UAT metrics logged successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Warning: Could not log UAT metrics: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# =============================================================================\n",
    "# ✅ REGISTER MODEL FROM UAT RUN WITH METRICS (CRITICAL FIX!)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"REGISTERING MODEL WITH UAT METRICS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    # ✅ IMPORTANT: Log model in UAT run so it's linked to UAT metrics\n",
    "    with mlflow.start_run(run_id=uat_run_id):\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            \"model\",\n",
    "            registered_model_name=MODEL_NAME\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Model logged in UAT run: {uat_run_id}\")\n",
    "    \n",
    "    # Get the newly created version - it will have UAT run_id\n",
    "    import time\n",
    "    time.sleep(3)  # Wait for registration to complete\n",
    "    \n",
    "    # Find the version that was just registered from our UAT run\n",
    "    model_versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "    \n",
    "    # Get version registered from our UAT run\n",
    "    uat_version = None\n",
    "    for v in model_versions:\n",
    "        if v.run_id == uat_run_id:\n",
    "            uat_version = v\n",
    "            break\n",
    "    \n",
    "    if not uat_version:\n",
    "        # Fallback: get latest version\n",
    "        uat_version = max(model_versions, key=lambda v: int(v.version))\n",
    "        print(f\"⚠ Warning: Could not find version by UAT run_id, using latest version\")\n",
    "    \n",
    "    print(f\"✓ Model registered as version: {uat_version.version}\")\n",
    "    print(f\"✓ Linked to UAT Run ID: {uat_version.run_id}\")\n",
    "    \n",
    "    # ✅ Remove old staging alias from previous version (if exists)\n",
    "    for v in model_versions:\n",
    "        version_detail = client.get_model_version(MODEL_NAME, v.version)\n",
    "        if STAGING_ALIAS in version_detail.aliases and v.version != uat_version.version:\n",
    "            print(f\"ℹ Removing '{STAGING_ALIAS}' alias from old version {v.version}\")\n",
    "            client.delete_registered_model_alias(MODEL_NAME, STAGING_ALIAS)\n",
    "            break\n",
    "    \n",
    "    # ✅ Set staging alias on new version\n",
    "    client.set_registered_model_alias(MODEL_NAME, STAGING_ALIAS, uat_version.version)\n",
    "    print(f\"✓ Alias '{STAGING_ALIAS}' set on version {uat_version.version}\")\n",
    "    \n",
    "    # Verify the alias was set correctly\n",
    "    time.sleep(1)\n",
    "    verified_version = client.get_model_version(MODEL_NAME, uat_version.version)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✅ MODEL REGISTRATION SUCCESSFUL\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Model Details:\")\n",
    "    print(f\"  Name: {MODEL_NAME}\")\n",
    "    print(f\"  Version: {uat_version.version}\")\n",
    "    print(f\"  Alias: {STAGING_ALIAS}\")\n",
    "    print(f\"  UAT Run ID: {uat_version.run_id}\")\n",
    "    print(f\"  Status: {verified_version.status}\")\n",
    "    print(f\"\\nMetrics Available in Run:\")\n",
    "    print(f\"  test_r2_score: {r2:.4f}\")\n",
    "    print(f\"  test_rmse: ${rmse:,.2f}\")\n",
    "    print(f\"  best_cv_rmse: ${best_cv_rmse:,.2f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during model registration: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION PASS/FAIL\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"UAT VALIDATION RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "validation_passed = True\n",
    "results = []\n",
    "\n",
    "if mape <= MAX_ACCEPTABLE_MAPE:\n",
    "    results.append(f\"✓ PASS: MAPE {mape:.2f}% <= {MAX_ACCEPTABLE_MAPE}%\")\n",
    "else:\n",
    "    results.append(f\"✗ FAIL: MAPE {mape:.2f}% > {MAX_ACCEPTABLE_MAPE}%\")\n",
    "    validation_passed = False\n",
    "\n",
    "if r2 >= MIN_ACCEPTABLE_R2:\n",
    "    results.append(f\"✓ PASS: R² {r2:.4f} >= {MIN_ACCEPTABLE_R2}\")\n",
    "else:\n",
    "    results.append(f\"✗ FAIL: R² {r2:.4f} < {MIN_ACCEPTABLE_R2}\")\n",
    "    validation_passed = False\n",
    "\n",
    "for res in results:\n",
    "    print(f\"  {res}\")\n",
    "\n",
    "if validation_passed:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"✅ UAT VALIDATION: PASSED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"Model is ready for Production promotion\")\n",
    "else:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"❌ UAT VALIDATION: FAILED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"Model does not meet quality thresholds\")\n",
    "    print(\"Please retrain with better parameters/data\")\n",
    "\n",
    "# =============================================================================\n",
    "# PREDICTION SAMPLE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_df = pandas_df.head(10)[['price', 'predicted_price', 'prediction_error', 'percentage_error']]\n",
    "print(sample_df.to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# ✅ FINGERPRINT LOGIC: Check if model is different from previous run\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"MODEL FINGERPRINT VALIDATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "def calculate_model_fingerprint(params_dict, metrics_dict):\n",
    "    \"\"\"Create a hash fingerprint from model params and key metrics\"\"\"\n",
    "    fingerprint_data = {\n",
    "        'params': {k: v for k, v in sorted(params_dict.items())},\n",
    "        'metrics': {\n",
    "            'r2': round(metrics_dict.get('test_r2_score', 0), 4),\n",
    "            'rmse': round(metrics_dict.get('test_rmse', 0), 2)\n",
    "        }\n",
    "    }\n",
    "    fingerprint_str = json.dumps(fingerprint_data, sort_keys=True)\n",
    "    return hashlib.md5(fingerprint_str.encode()).hexdigest()\n",
    "\n",
    "# Calculate current model fingerprint\n",
    "current_fingerprint = calculate_model_fingerprint(\n",
    "    training_params,\n",
    "    {'test_r2_score': r2, 'test_rmse': rmse}\n",
    ")\n",
    "\n",
    "print(f\"Current Model Fingerprint: {current_fingerprint}\")\n",
    "\n",
    "# Check if previous results exist\n",
    "RESULTS_TABLE = f\"{DATA_CATALOG_NAME}.{DATA_SCHEMA_NAME}.uat_inference_results\"\n",
    "previous_fingerprint = None\n",
    "is_new_model = True\n",
    "\n",
    "try:\n",
    "    # Try to read existing results table\n",
    "    existing_results = spark.read.format(\"delta\").table(RESULTS_TABLE)\n",
    "    \n",
    "    if existing_results.count() > 0:\n",
    "        # Get the most recent fingerprint\n",
    "        latest_result = existing_results.orderBy(col(\"inference_timestamp\").desc()).first()\n",
    "        previous_fingerprint = latest_result['model_fingerprint']\n",
    "        \n",
    "        print(f\"Previous Model Fingerprint: {previous_fingerprint}\")\n",
    "        \n",
    "        if current_fingerprint == previous_fingerprint:\n",
    "            is_new_model = False\n",
    "            print(\"✓ Model fingerprint MATCHES previous run - Will UPDATE existing table\")\n",
    "        else:\n",
    "            is_new_model = True\n",
    "            print(\"✓ Model fingerprint DIFFERENT - Will CREATE new table version\")\n",
    "    else:\n",
    "        print(\"ℹ No previous results found - Will CREATE new table\")\n",
    "        is_new_model = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ℹ Results table doesn't exist yet - Will CREATE new table\")\n",
    "    is_new_model = True\n",
    "\n",
    "# =============================================================================\n",
    "# ✅ SAVE RESULTS TO DELTA TABLE (Based on Fingerprint)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING UAT RESULTS TO DELTA TABLE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "try:\n",
    "    # Prepare results dataframe\n",
    "    results_df = pandas_df.copy()\n",
    "    results_df['inference_timestamp'] = datetime.now()\n",
    "    results_df['model_version'] = latest_version.version\n",
    "    results_df['model_run_id'] = uat_run_id\n",
    "    results_df['model_fingerprint'] = current_fingerprint\n",
    "    results_df['uat_r2_score'] = r2\n",
    "    results_df['uat_rmse'] = rmse\n",
    "    results_df['uat_mae'] = mae\n",
    "    results_df['uat_mape'] = mape\n",
    "    results_df['validation_passed'] = validation_passed\n",
    "    \n",
    "    # Convert to Spark DataFrame\n",
    "    spark_results_df = spark.createDataFrame(results_df)\n",
    "    \n",
    "    if is_new_model:\n",
    "        # ✅ NEW MODEL: Overwrite or create table\n",
    "        print(\"Action: OVERWRITE - Creating new table version\")\n",
    "        spark_results_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(RESULTS_TABLE)\n",
    "        print(f\"✓ New results saved to: {RESULTS_TABLE}\")\n",
    "        \n",
    "    else:\n",
    "        # ✅ SAME MODEL: Append to existing table\n",
    "        print(\"Action: APPEND - Updating existing table\")\n",
    "        spark_results_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .saveAsTable(RESULTS_TABLE)\n",
    "        print(f\"✓ Results appended to: {RESULTS_TABLE}\")\n",
    "    \n",
    "    # Show table info\n",
    "    result_count = spark.read.format(\"delta\").table(RESULTS_TABLE).count()\n",
    "    print(f\"\\nTable Statistics:\")\n",
    "    print(f\"  Table: {RESULTS_TABLE}\")\n",
    "    print(f\"  Total Rows: {result_count}\")\n",
    "    print(f\"  Model Fingerprint: {current_fingerprint}\")\n",
    "    print(f\"  Strategy: {'NEW VERSION (Overwrite)' if is_new_model else 'UPDATE (Append)'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Warning: Could not save results to Delta table: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# =============================================================================\n",
    "# EXIT\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"UAT INFERENCE COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "exit_status = \"PASSED\" if validation_passed else \"FAILED\"\n",
    "print(f\"Status: {exit_status}\")\n",
    "print(f\"Model Fingerprint: {current_fingerprint}\")\n",
    "print(f\"Results Table: {RESULTS_TABLE}\")\n",
    "\n",
    "try:\n",
    "    dbutils.notebook.exit(exit_status)\n",
    "except:\n",
    "    if not validation_passed:\n",
    "        raise Exception(\"UAT Validation Failed: Model does not meet quality thresholds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
