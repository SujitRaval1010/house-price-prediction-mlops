{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================\n",
    "# ‚úÖ UAT MODEL INFERENCE SCRIPT (FINAL VERSION ‚Äì ALIGNED WITH STAGING LOGIC)\n",
    "# =============================================================\n",
    "%pip install xgboost\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ CONFIGURATION (FIXED ‚Äî SAME AS YOUR STAGING SCRIPT)\n",
    "# =============================================================\n",
    "UC_CATALOG = \"workspace\"\n",
    "UC_SCHEMA = \"ml\"\n",
    "MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.house_price_xgboost_uc2\"\n",
    "\n",
    "# Delta input table for UAT\n",
    "DELTA_INPUT_TABLE = \"workspace.default.house_price_delta\"\n",
    "\n",
    "# Thresholds for validation\n",
    "MAPE_THRESHOLD = 15.0   # target < 15%\n",
    "R2_THRESHOLD   = 0.75   # target > 0.75\n",
    "\n",
    "# Output table\n",
    "OUTPUT_TABLE = \"workspace.default.uat_inference_house_price_xgboost\"\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ INITIALIZATION\n",
    "# =============================================================\n",
    "spark = SparkSession.builder.appName(\"UAT_Inference_Fixed\").getOrCreate()\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ UAT MODEL INFERENCE STARTED ‚Äì FIXED VERSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 1Ô∏è‚É£ Load model from STAGING alias (exact match with staging script)\n",
    "# =============================================================\n",
    "def load_staging_model(model_name):\n",
    "    print(f\"\\nüìå Loading UC model from alias: @Staging\")\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}@Staging\"\n",
    "        model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "        mv = client.get_model_version_by_alias(model_name, \"Staging\")\n",
    "\n",
    "        print(f\"‚úÖ Loaded model version: v{mv.version}\")\n",
    "        print(f\"‚úÖ Run ID: {mv.run_id}\")\n",
    "        return model, mv.version, mv.run_id\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"‚ùå Failed to load model from staging: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 2Ô∏è‚É£ Load Delta table for inference\n",
    "# =============================================================\n",
    "def load_data():\n",
    "    print(\"\\nüìå Loading UAT Delta input data...\")\n",
    "    try:\n",
    "        df_spark = spark.table(DELTA_INPUT_TABLE)\n",
    "        df = df_spark.toPandas()\n",
    "\n",
    "        if \"price\" not in df.columns:\n",
    "            raise ValueError(\"‚ùå Input table MUST contain 'price' column.\")\n",
    "\n",
    "        X = df.drop(columns=[\"price\"])\n",
    "        y_true = df[\"price\"]\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(df)} rows for inference.\")\n",
    "        return df, X, y_true\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"‚ùå Failed to load input table: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 3Ô∏è‚É£ Run inference\n",
    "# =============================================================\n",
    "def run_inference(model, X):\n",
    "    print(\"\\nüìå Running inference...\")\n",
    "    y_pred = model.predict(X)\n",
    "    print(\"‚úÖ Inference complete.\")\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 4Ô∏è‚É£ Calculate metrics\n",
    "# =============================================================\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    print(\"\\nüìä Evaluation Metrics:\")\n",
    "    print(f\"MAE  : {mae:.3f}\")\n",
    "    print(f\"RMSE : {rmse:.3f}\")\n",
    "    print(f\"R¬≤   : {r2:.3f}\")\n",
    "    print(f\"MAPE : {mape:.2f}%\")\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 5Ô∏è‚É£ Threshold validation (UAT pass/fail)\n",
    "# =============================================================\n",
    "def validate(mape, r2):\n",
    "    if mape <= MAPE_THRESHOLD and r2 >= R2_THRESHOLD:\n",
    "        print(\"\\n‚úÖ UAT PASSED ‚úÖ\")\n",
    "        return \"PASSED\"\n",
    "    else:\n",
    "        print(\"\\n‚ùå UAT FAILED ‚ùå\")\n",
    "        return \"FAILED\"\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 6Ô∏è‚É£ Log results to Delta table (dedupe included)\n",
    "# =============================================================\n",
    "def log_results(model_version, mae, rmse, r2, mape, status):\n",
    "    result_df = pd.DataFrame([{\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"model_version\": int(model_version),\n",
    "        \"mae\": mae,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "        \"mape\": mape,\n",
    "        \"uat_status\": status\n",
    "    }])\n",
    "\n",
    "    # Prevent duplicate logs\n",
    "    try:\n",
    "        existing = spark.table(OUTPUT_TABLE).toPandas()\n",
    "        if not existing.empty:\n",
    "            last = existing.iloc[-1]\n",
    "            if (\n",
    "                math.isclose(last.mae, mae, rel_tol=1e-6) and\n",
    "                math.isclose(last.rmse, rmse, rel_tol=1e-6) and\n",
    "                math.isclose(last.r2, r2, rel_tol=1e-6) and\n",
    "                math.isclose(last.mape, mape, rel_tol=1e-6)\n",
    "            ):\n",
    "                print(\"\\n‚ÑπÔ∏è Metrics unchanged ‚Üí Skipping log\")\n",
    "                return\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    spark_df = spark.createDataFrame(result_df)\n",
    "    spark_df.write.mode(\"append\").saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "    print(f\"\\nüìù Logged results to: {OUTPUT_TABLE}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ MAIN EXECUTION FLOW\n",
    "# =============================================================\n",
    "try:\n",
    "    model, model_version, run_id = load_staging_model(MODEL_NAME)\n",
    "    df, X, y_true = load_data()\n",
    "    y_pred = run_inference(model, X)\n",
    "    mae, rmse, r2, mape = evaluate(y_true, y_pred)\n",
    "    status = validate(mape, r2)\n",
    "    log_results(model_version, mae, rmse, r2, mape, status)\n",
    "\n",
    "    print(\"\\nüéØ UAT INFERENCE COMPLETED SUCCESSFULLY\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå UAT ERROR: {str(e)}\")\n",
    "    sys.exit(1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
