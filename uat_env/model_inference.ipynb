{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================\n",
    "# ‚úÖ UAT MODEL INFERENCE SCRIPT (ALIGNED WITH REGISTRATION & STAGING)\n",
    "# =============================================================\n",
    "# COMMAND ----------\n",
    "%pip install xgboost\n",
    "\n",
    "# COMMAND ----------\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ CONFIGURATION (ALIGNED WITH REGISTRATION & STAGING SCRIPTS)\n",
    "# =============================================================\n",
    "UC_CATALOG = \"workspace\"\n",
    "UC_SCHEMA = \"ml\"\n",
    "MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.house_price_xgboost_uc2\"\n",
    "STAGING_ALIAS = \"Staging\"\n",
    "\n",
    "# Delta input table for UAT inference\n",
    "DELTA_INPUT_TABLE = \"workspace.default.house_price_delta\"\n",
    "\n",
    "# Feature columns (must match training script)\n",
    "FEATURE_COLS = ['sq_feet', 'num_bedrooms', 'num_bathrooms', 'year_built', 'location_score']\n",
    "LABEL_COL = 'price'\n",
    "\n",
    "# Thresholds for validation\n",
    "MAPE_THRESHOLD = 15.0   # target < 15%\n",
    "R2_THRESHOLD   = 0.75   # target > 0.75\n",
    "\n",
    "# Output table for UAT results\n",
    "OUTPUT_TABLE = \"workspace.default.uat_inference_house_price_xgboost\"\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ INITIALIZATION\n",
    "# =============================================================\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ UAT MODEL INFERENCE - ALIGNED VERSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"UAT_Inference_Aligned\").getOrCreate()\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Alias: {STAGING_ALIAS}\")\n",
    "print(f\"   Input Table: {DELTA_INPUT_TABLE}\")\n",
    "print(f\"   Output Table: {OUTPUT_TABLE}\")\n",
    "print(f\"   Feature Columns: {FEATURE_COLS}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 1Ô∏è‚É£ Load model from STAGING alias\n",
    "# =============================================================\n",
    "def load_staging_model(model_name, alias):\n",
    "    \"\"\"\n",
    "    Load model from Unity Catalog using alias (aligned with staging script)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìã STEP 1: Loading Model from @{alias}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}@{alias}\"\n",
    "        print(f\"   Model URI: {model_uri}\")\n",
    "        \n",
    "        model = mlflow.pyfunc.load_model(model_uri)\n",
    "        mv = client.get_model_version_by_alias(model_name, alias)\n",
    "\n",
    "        print(f\"\\n‚úÖ Model Loaded Successfully!\")\n",
    "        print(f\"   Version: v{mv.version}\")\n",
    "        print(f\"   Run ID: {mv.run_id}\")\n",
    "        print(f\"   Status: {mv.status}\")\n",
    "        \n",
    "        # Get metric from tags if available\n",
    "        metric_tag = mv.tags.get(\"metric_rmse\", \"N/A\")\n",
    "        print(f\"   Training RMSE: {metric_tag}\")\n",
    "        \n",
    "        return model, mv.version, mv.run_id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed to load model from {alias}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise ValueError(f\"Model loading failed: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 2Ô∏è‚É£ Load Delta table for inference\n",
    "# =============================================================\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load UAT data from Delta table with proper feature selection\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 2: Loading UAT Data\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        df_spark = spark.table(DELTA_INPUT_TABLE)\n",
    "        df = df_spark.toPandas()\n",
    "\n",
    "        print(f\"   Total rows loaded: {len(df)}\")\n",
    "        print(f\"   Columns: {list(df.columns)}\")\n",
    "\n",
    "        # Validate required columns exist\n",
    "        missing_features = [col for col in FEATURE_COLS if col not in df.columns]\n",
    "        if missing_features:\n",
    "            raise ValueError(f\"Missing feature columns: {missing_features}\")\n",
    "\n",
    "        if LABEL_COL not in df.columns:\n",
    "            raise ValueError(f\"Missing label column: {LABEL_COL}\")\n",
    "\n",
    "        # Select only required features and label\n",
    "        X = df[FEATURE_COLS]\n",
    "        y_true = df[LABEL_COL]\n",
    "\n",
    "        print(f\"\\n‚úÖ Data Loaded Successfully!\")\n",
    "        print(f\"   Features shape: {X.shape}\")\n",
    "        print(f\"   Labels shape: {y_true.shape}\")\n",
    "        \n",
    "        return df, X, y_true\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed to load input table: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise ValueError(f\"Data loading failed: {e}\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 3Ô∏è‚É£ Run inference\n",
    "# =============================================================\n",
    "def run_inference(model, X):\n",
    "    \"\"\"\n",
    "    Run model inference on UAT data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 3: Running Inference\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"   Running predictions on {len(X)} samples...\")\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Inference Complete!\")\n",
    "        print(f\"   Predictions generated: {len(y_pred)}\")\n",
    "        print(f\"   Sample predictions: {y_pred[:5]}\")\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Inference failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 4Ô∏è‚É£ Calculate metrics\n",
    "# =============================================================\n",
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics for UAT\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Evaluating Model Performance\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "        print(f\"\\nüìä Evaluation Metrics:\")\n",
    "        print(f\"   MAE  : {mae:.3f}\")\n",
    "        print(f\"   RMSE : {rmse:.3f}\")\n",
    "        print(f\"   R¬≤   : {r2:.3f}\")\n",
    "        print(f\"   MAPE : {mape:.2f}%\")\n",
    "        \n",
    "        return mae, rmse, r2, mape\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Evaluation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 5Ô∏è‚É£ Threshold validation (UAT pass/fail)\n",
    "# =============================================================\n",
    "def validate(mape, r2):\n",
    "    \"\"\"\n",
    "    Validate model performance against UAT thresholds\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 5: UAT Validation\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\nüìè Validation Thresholds:\")\n",
    "    print(f\"   MAPE threshold: ‚â§ {MAPE_THRESHOLD}%\")\n",
    "    print(f\"   R¬≤ threshold:   ‚â• {R2_THRESHOLD}\")\n",
    "    \n",
    "    print(f\"\\nüìä Actual Performance:\")\n",
    "    print(f\"   MAPE: {mape:.2f}% {'‚úÖ' if mape <= MAPE_THRESHOLD else '‚ùå'}\")\n",
    "    print(f\"   R¬≤:   {r2:.3f}  {'‚úÖ' if r2 >= R2_THRESHOLD else '‚ùå'}\")\n",
    "    \n",
    "    if mape <= MAPE_THRESHOLD and r2 >= R2_THRESHOLD:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ‚úÖ UAT PASSED ‚úÖ‚úÖ\")\n",
    "        print(f\"{'='*70}\")\n",
    "        return \"PASSED\"\n",
    "    else:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚ùå‚ùå UAT FAILED ‚ùå‚ùå\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Show which criteria failed\n",
    "        if mape > MAPE_THRESHOLD:\n",
    "            print(f\"   ‚ö†Ô∏è MAPE too high: {mape:.2f}% > {MAPE_THRESHOLD}%\")\n",
    "        if r2 < R2_THRESHOLD:\n",
    "            print(f\"   ‚ö†Ô∏è R¬≤ too low: {r2:.3f} < {R2_THRESHOLD}\")\n",
    "        \n",
    "        return \"FAILED\"\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ 6Ô∏è‚É£ Log results to Delta table (with deduplication)\n",
    "# =============================================================\n",
    "def log_results(model_version, run_id, mae, rmse, r2, mape, status):\n",
    "    \"\"\"\n",
    "    Log UAT results to Delta table with duplicate prevention\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 6: Logging Results\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        result_df = pd.DataFrame([{\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"model_version\": int(model_version),\n",
    "            \"run_id\": run_id,\n",
    "            \"mae\": float(mae),\n",
    "            \"rmse\": float(rmse),\n",
    "            \"r2\": float(r2),\n",
    "            \"mape\": float(mape),\n",
    "            \"uat_status\": status\n",
    "        }])\n",
    "\n",
    "        # Check for duplicates\n",
    "        try:\n",
    "            existing = spark.table(OUTPUT_TABLE).toPandas()\n",
    "            if not existing.empty:\n",
    "                last = existing.iloc[-1]\n",
    "                \n",
    "                # Check if metrics are identical to last run\n",
    "                is_duplicate = (\n",
    "                    int(last.model_version) == int(model_version) and\n",
    "                    math.isclose(float(last.mae), mae, rel_tol=1e-6) and\n",
    "                    math.isclose(float(last.rmse), rmse, rel_tol=1e-6) and\n",
    "                    math.isclose(float(last.r2), r2, rel_tol=1e-6) and\n",
    "                    math.isclose(float(last.mape), mape, rel_tol=1e-6)\n",
    "                )\n",
    "                \n",
    "                if is_duplicate:\n",
    "                    print(\"\\n‚ÑπÔ∏è Duplicate Entry Detected\")\n",
    "                    print(\"   Metrics unchanged from last run ‚Üí Skipping log\")\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"   Note: Could not check for duplicates (table may not exist): {e}\")\n",
    "\n",
    "        # Write to Delta table\n",
    "        spark_df = spark.createDataFrame(result_df)\n",
    "        spark_df.write.mode(\"append\").saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "        print(f\"\\n‚úÖ Results Logged Successfully!\")\n",
    "        print(f\"   Output Table: {OUTPUT_TABLE}\")\n",
    "        print(f\"   Model Version: v{model_version}\")\n",
    "        print(f\"   UAT Status: {status}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed to log results: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ MAIN EXECUTION FLOW\n",
    "# =============================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution flow for UAT inference\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üé¨ STARTING UAT INFERENCE PIPELINE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Step 1: Load model\n",
    "        model, model_version, run_id = load_staging_model(MODEL_NAME, STAGING_ALIAS)\n",
    "        \n",
    "        # Step 2: Load data\n",
    "        df, X, y_true = load_data()\n",
    "        \n",
    "        # Step 3: Run inference\n",
    "        y_pred = run_inference(model, X)\n",
    "        \n",
    "        # Step 4: Evaluate\n",
    "        mae, rmse, r2, mape = evaluate(y_true, y_pred)\n",
    "        \n",
    "        # Step 5: Validate\n",
    "        status = validate(mape, r2)\n",
    "        \n",
    "        # Step 6: Log results\n",
    "        log_results(model_version, run_id, mae, rmse, r2, mape, status)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ú® UAT INFERENCE COMPLETED SUCCESSFULLY ‚ú®\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nüìä Summary:\")\n",
    "        print(f\"   Model Version: v{model_version}\")\n",
    "        print(f\"   UAT Status: {status}\")\n",
    "        print(f\"   RMSE: {rmse:.3f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        print(f\"   R¬≤: {r2:.3f}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ùå UAT INFERENCE FAILED\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# ‚úÖ EXECUTE\n",
    "# =============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
