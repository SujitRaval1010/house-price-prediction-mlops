import os
import time
from databricks.sdk import WorkspaceClient
from databricks.sdk.service import jobs
from databricks.sdk.service.jobs import TaskDependency

# Initialize Databricks client
try:
    w = WorkspaceClient()
    print("‚úÖ Databricks client initialized successfully")
except Exception as e:
    print(f"‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: Databricks ‡§ï‡•ç‡§≤‡§æ‡§á‡§Ç‡§ü ‡§ï‡•ã ‡§Ü‡§∞‡§Ç‡§≠ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§´‡§≤‡•§")
    print(f"   ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø DATABRICKS_HOST ‡§î‡§∞ DATABRICKS_TOKEN ‡§∏‡•á‡§ü ‡§π‡•à‡§Ç‡•§")
    print(f"   ‡§µ‡§ø‡§µ‡§∞‡§£: {e}")
    exit(1)

# Configuration
repo_name = "house-price-prediction-mlops"
repo_path = f"/Repos/vipultak7171@gmail.com/{repo_name}"

print("\n" + "=" * 60)
print("üöÄ MLOPS PIPELINE ORCHESTRATION (Serverless)")
print("=" * 60)
print(f"üìÅ Repository Path: {repo_path}")
print("-" * 60 + "\n")

# ==============================================================================
# HELPER FUNCTIONS
# ==============================================================================

def get_job_id(job_name):
    """‡§®‡§æ‡§Æ ‡§∏‡•á ‡§Æ‡•å‡§ú‡•Ç‡§¶‡§æ Databricks Job ID ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§"""
    try:
        job = next(j for j in w.jobs.list() if j.settings.name == job_name)
        return job.job_id
    except StopIteration:
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä: Job list ‡§ï‡§∞‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
        return None


def create_or_update_job(job_name, tasks, auto_run=False):
    """
    Job ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à, ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§∏‡•á ‡§ü‡•ç‡§∞‡§ø‡§ó‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
    Serverless compute ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ã‡§à cluster configuration ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§®‡§π‡•Ä‡§Ç‡•§
    """
    try:
        existing_job_id = get_job_id(job_name)
        
        # Serverless ‡§ï‡•á ‡§≤‡§ø‡§è job_clusters parameter ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§æ‡§π‡§ø‡§è
        job_settings = jobs.JobSettings(
            name=job_name,
            tasks=tasks,
            # Serverless automatically compute allocate ‡§ï‡§∞‡§§‡§æ ‡§π‡•à
            max_concurrent_runs=1  # ‡§è‡§ï ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§π‡•Ä run
        )
        
        if existing_job_id:
            print(f"üîÑ Job ‡§ï‡•ã ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à: {job_name} (ID: {existing_job_id})")
            w.jobs.reset(job_id=existing_job_id, new_settings=job_settings)
            job_id = existing_job_id
        else:
            print(f"‚ûï ‡§®‡§Ø‡§æ Job ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à: {job_name}")
            result = w.jobs.create(
                name=job_settings.name,
                tasks=job_settings.tasks,
                max_concurrent_runs=1
            )
            job_id = result.job_id
            
        print(f"‚úÖ Job '{job_name}' ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à (ID: {job_id})")
        
        if auto_run:
            print(f"üöÄ Job ‡§ï‡•ã ‡§ë‡§ü‡•ã-‡§ü‡•ç‡§∞‡§ø‡§ó‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à: {job_name}")
            run_result = w.jobs.run_now(job_id=job_id)
            print(f"   üìã Run ID: {run_result.run_id}")
            return job_id, run_result.run_id
            
        return job_id, None
        
    except Exception as e:
        print(f"‚ùå Job '{job_name}' ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
        print(f"   ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {str(e)}")
        return None, None


def wait_for_job_completion(job_id, run_id, job_name, timeout_minutes=30):
    """Job ‡§ï‡•á ‡§™‡•Ç‡§∞‡§æ ‡§π‡•ã‡§®‡•á ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡•Ä ‡§ú‡§æ‡§Å‡§ö ‡§ï‡§∞‡•á‡§Ç‡•§"""
    if not run_id:
        return False
        
    print(f"\n‚è≥ {job_name} ‡§ï‡•á ‡§™‡•Ç‡§∞‡§æ ‡§π‡•ã‡§®‡•á ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à...")
    print(f"   (‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§∏‡§Æ‡§Ø: {timeout_minutes} ‡§Æ‡§ø‡§®‡§ü)")
    
    timeout_seconds = timeout_minutes * 60
    start_time = time.time()
    last_state = None
    
    while time.time() - start_time < timeout_seconds:
        try:
            run_info = w.jobs.get_run(run_id=run_id)
            state = run_info.state.life_cycle_state.value if run_info.state and run_info.state.life_cycle_state else "UNKNOWN"
            
            # State change ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§π‡•Ä print ‡§ï‡§∞‡•á‡§Ç
            if state != last_state:
                print(f"   üìä {job_name} ‡§∏‡•ç‡§•‡§ø‡§§‡§ø: {state}")
                last_state = state
            
            if state == "TERMINATED":
                result_state = run_info.state.result_state.value if run_info.state and run_info.state.result_state else "UNKNOWN"
                if result_state == "SUCCESS":
                    elapsed_time = int(time.time() - start_time)
                    print(f"‚úÖ {job_name} ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü! (‡§∏‡§Æ‡§Ø: {elapsed_time}s)")
                    return True
                else:
                    print(f"‚ùå {job_name} ‡§µ‡§ø‡§´‡§≤ ‡§π‡•ã ‡§ó‡§Ø‡§æ‡•§ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø: {result_state}")
                    if run_info.state.state_message:
                        print(f"   ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§∏‡§Ç‡§¶‡•á‡§∂: {run_info.state.state_message}")
                    return False
            
            time.sleep(15)  # ‡§π‡§∞ 15 ‡§∏‡•á‡§ï‡§Ç‡§° ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§Å‡§ö ‡§ï‡§∞‡•á‡§Ç
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ú‡§æ‡§Å‡§ö‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
            time.sleep(30)
    
    print(f"‚è∞ {job_name} ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡§æ‡§á‡§Æ‡§Ü‡§â‡§ü ‡§π‡•ã ‡§ó‡§Ø‡§æ ({timeout_minutes} ‡§Æ‡§ø‡§®‡§ü)‡•§")
    return False


# ==============================================================================
# 1. DEV JOB CREATION (Data Ingest -> Train -> Register)
# ==============================================================================
print("\n[STEP 1/3] üõ†Ô∏è DEV Training Pipeline ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...")
print("-" * 60)

dev_tasks = [
    # Task 1: Data Ingestion and Preparation
    jobs.Task(
        task_key="data_ingest_and_prep_task",
        description="Ingests and prepares data for training",
        notebook_task=jobs.NotebookTask(
            notebook_path=f"{repo_path}/dev_env/Data_Ingestion_and_Preparation",
            base_parameters={"environment": "development"}
        )
        # Serverless compute automatically assign ‡§π‡•ã‡§ó‡§æ, ‡§ï‡•ã‡§à cluster key ‡§®‡§π‡•Ä‡§Ç
    ),
    
    # Task 2: Model Training
    jobs.Task(
        task_key="model_training_task",
        description="Trains the model using prepared data",
        notebook_task=jobs.NotebookTask(
            notebook_path=f"{repo_path}/dev_env/Model_Training",
            base_parameters={"environment": "development"}
        ),
        depends_on=[TaskDependency(task_key="data_ingest_and_prep_task")]
    ),
    
    # Task 3: Model Registration
    jobs.Task(
        task_key="model_registration_task",
        description="Registers the trained model to Unity Catalog",
        notebook_task=jobs.NotebookTask(
            notebook_path=f"{repo_path}/dev_env/Model_Registration",
            base_parameters={"environment": "development"}
        ),
        depends_on=[TaskDependency(task_key="model_training_task")]
    )
]

dev_job_id, dev_run_id = create_or_update_job(
    job_name="1. dev-ml-training-pipeline", 
    tasks=dev_tasks,
    auto_run=True 
)

# ==============================================================================
# WAIT FOR DEV COMPLETION
# ==============================================================================
if dev_job_id and dev_run_id:
    dev_success = wait_for_job_completion(
        dev_job_id, 
        dev_run_id, 
        "DEV Training Pipeline", 
        timeout_minutes=25
    )
else:
    print("\n‚ùå DEV Job ‡§ï‡•ã ‡§ü‡•ç‡§∞‡§ø‡§ó‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§æ‡•§ Pipeline ‡§∞‡•ã‡§ï ‡§∞‡§π‡§æ ‡§π‡•à‡•§")
    exit(1)

# ==============================================================================
# 2. UAT JOB CREATION (Staging -> Inference Test)
# ==============================================================================
if dev_success:
    print("\n[STEP 2/3] üß™ UAT Testing Pipeline ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...")
    print("-" * 60)
    
    uat_tasks = [
        # Task 1: Model Staging
        jobs.Task(
            task_key="model_staging_task",
            description="Promotes the latest model version to Staging alias",
            notebook_task=jobs.NotebookTask(
                notebook_path=f"{repo_path}/uat_env/model_staging_uat", 
                base_parameters={"alias": "Staging"}
            )
        ),
        
        # Task 2: Inference Test
        jobs.Task(
            task_key="inference_test_task",
            description="Runs inference tests against the Staging model",
            notebook_task=jobs.NotebookTask(
                notebook_path=f"{repo_path}/uat_env/Model-Inference",
                base_parameters={"alias": "Staging", "environment": "uat"}
            ),
            depends_on=[TaskDependency(task_key="model_staging_task")]
        )
    ]
    
    uat_job_id, uat_run_id = create_or_update_job(
        job_name="2. uat-ml-inference-pipeline",
        tasks=uat_tasks,
        auto_run=True 
    )
    
    # Wait for UAT completion
    if uat_job_id and uat_run_id:
        uat_success = wait_for_job_completion(
            uat_job_id, 
            uat_run_id, 
            "UAT Testing Pipeline", 
            timeout_minutes=20
        )
    else:
        print("\n‚ùå UAT Job ‡§ï‡•ã ‡§ü‡•ç‡§∞‡§ø‡§ó‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§æ‡•§ Pipeline ‡§∞‡•ã‡§ï ‡§∞‡§π‡§æ ‡§π‡•à‡•§")
        uat_success = False
    
    # ==========================================================================
    # 3. PROD JOB CREATION (Promotion -> Serving Endpoint)
    # ==========================================================================
    if uat_success:
        print("\n[STEP 3/3] üöÄ PROD Deployment Pipeline ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...")
        print("-" * 60)
        
        prod_tasks = [
            # Task 1: Model Promotion
            jobs.Task(
                task_key="model_promotion_task",
                description="Promotes the model from Staging to Production alias",
                notebook_task=jobs.NotebookTask(
                    notebook_path=f"{repo_path}/prod_env/model-promotion", 
                    base_parameters={"alias": "Production", "action": "promote"}
                )
            ),
            
            # Task 2: Serving Endpoint Deployment
            jobs.Task(
                task_key="serving_endpoint_task",
                description="Creates/updates Serving Endpoint with Production model",
                notebook_task=jobs.NotebookTask(
                    notebook_path=f"{repo_path}/prod_env/create-serving-endpoint", 
                    base_parameters={"environment": "prod"}
                ),
                depends_on=[TaskDependency(task_key="model_promotion_task")]
            ),
            # Task 3: Model Inference in Production
            jobs.Task(
                task_key="model_inference_production",
                description="Runs inference tests against the Production model",
                notebook_task=jobs.NotebookTask(
                    notebook_path=f"{repo_path}/prod_env/Model-Inference",
                    base_parameters={"alias": "Production", "environment": "prod"}
                ),
                depends_on=[TaskDependency(task_key="serving_endpoint_task")]
            )
        ]
         
        prod_job_id, prod_run_id = create_or_update_job(
            job_name="3. prod-ml-deployment-pipeline",
            tasks=prod_tasks,
            auto_run=True 
        )
        
        # Wait for PROD completion
        if prod_job_id and prod_run_id:
            prod_success = wait_for_job_completion(
                prod_job_id, 
                prod_run_id, 
                "PROD Deployment Pipeline", 
                timeout_minutes=30
            )
            
            if prod_success:
                print("\n" + "=" * 60)
                print("üéâ MLOPS PIPELINE EXECUTION SUCCESSFUL! üéâ")
                print("=" * 60)
                print("‚úÖ DEV: Model trained and registered")
                print("‚úÖ UAT: Model validated in staging")
                print("‚úÖ PROD: Model deployed to production")
                print("=" * 60)
                print("\nüí° Next Steps:")
                print("   1. Check your Unity Catalog for registered models")
                print("   2. Verify the Serving Endpoint in Databricks UI")
                print("   3. Test the production endpoint with sample data")
                print("=" * 60)
            else:
                print("\n‚ùå PROD Pipeline ‡§µ‡§ø‡§´‡§≤ ‡§∞‡§π‡§æ‡•§ Deployment logs ‡§ú‡§æ‡§Å‡§ö‡•á‡§Ç‡•§")
        else:
            print("\n‚ùå PROD Job ‡§ï‡•ã ‡§ü‡•ç‡§∞‡§ø‡§ó‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§æ‡•§")
    else:
        print("\n‚è≠Ô∏è UAT Pipeline ‡§µ‡§ø‡§´‡§≤ ‡§∞‡§π‡§æ, PROD deployment ‡§õ‡•ã‡§°‡§º ‡§∞‡§π‡§æ ‡§π‡•à‡•§")
else:
    print("\n‚è≠Ô∏è DEV Pipeline ‡§µ‡§ø‡§´‡§≤ ‡§∞‡§π‡§æ, ‡§Ü‡§ó‡•á ‡§ï‡•Ä pipelines ‡§õ‡•ã‡§°‡§º ‡§∞‡§π‡§æ ‡§π‡•à‡•§")

print("\n" + "=" * 60)
print("üèÅ MLOps Pipeline Orchestration Script Complete!")
print("=" * 60)