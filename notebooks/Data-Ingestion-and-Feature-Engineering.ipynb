{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac55ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01-Data-Ingestion-and-Feature-Engineering.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# डमी डेटा बनाना\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "\n",
    "data = {\n",
    "    'sq_feet': np.random.randint(800, 3000, num_samples),\n",
    "    'num_bedrooms': np.random.randint(2, 6, num_samples),\n",
    "    'num_bathrooms': np.random.randint(1, 4, num_samples),\n",
    "    'year_built': np.random.randint(1990, 2023, num_samples),\n",
    "    'location_score': np.random.rand(num_samples) * 10\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# हाउस प्राइस का अनुमान लगाना (डमी)\n",
    "df['price'] = (df['sq_feet'] * 150 +\n",
    "               df['num_bedrooms'] * 20000 +\n",
    "               df['num_bathrooms'] * 15000 +\n",
    "               (df['year_built'] - 1990) * 500 +\n",
    "               df['location_score'] * 10000 +\n",
    "               np.random.normal(0, 10000, num_samples))\n",
    "\n",
    "# Pandas DataFrame को PySpark DataFrame में बदलना\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# डेल्टा टेबल के रूप में डेटा को सेव करना\n",
    "# हम एक डेल्टा लेक फ़ाइल पाथ बनाएंगे जो सभी लेयर्स के लिए कॉमन होगी\n",
    "delta_table_path = \"/tmp/house_price_prediction_data\"\n",
    "\n",
    "spark_df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "\n",
    "print(\"डमी डेटा सफलतापूर्वक डेल्टा टेबल के रूप में सेव किया गया है।\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
