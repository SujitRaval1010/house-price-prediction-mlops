{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# model_train.py\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from mlflow.models.signature import infer_signature # ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§ø‡§ó‡•ç‡§®‡•á‡§ö‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä (Warnings) ‡§ï‡•ã ‡§Ö‡§®‡§¶‡•á‡§ñ‡§æ ‡§ï‡§∞‡•á‡§Ç\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "EXPERIMENT_NAME = \"/Shared/House_Price_Prediction_Delta_RF\"\n",
    "MODEL_ARTIFACT_PATH = \"sklearn_rf_model\"\n",
    "DELTA_TABLE_NAME = \"house_price_delta\" \n",
    "\n",
    "# ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§®\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "FEATURE_COLS = ['sq_feet', 'num_bedrooms', 'num_bathrooms', 'year_built', 'location_score']\n",
    "LABEL_COL = 'price'\n",
    "\n",
    "# Cross-validation ‡§ï‡•á ‡§≤‡§ø‡§è parameter grid\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 12, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "CV_FOLDS = 3\n",
    "\n",
    "# ==================== FUNCTIONS ====================\n",
    "\n",
    "def setup_mlflow_experiment():\n",
    "    \"\"\"MLflow ‡§ü‡•ç‡§∞‡•à‡§ï‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§ï‡•ã Databricks UC ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\"\"\"\n",
    "    if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(\"databricks\") \n",
    "            # UC ‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à\n",
    "            mlflow.set_registry_uri(\"databricks-uc\") \n",
    "            print(\"‚úì MLflow configured for Databricks UC (Tracking & Registry).\")\n",
    "        except Exception as e:\n",
    "            # ‡§Ø‡§¶‡§ø ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞‡•á‡§∂‡§® ‡§µ‡§ø‡§´‡§≤ ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç ‡§≤‡•á‡§ï‡§ø‡§® ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§¶‡•á‡§Ç\n",
    "            print(f\"‚ö† Warning: MLflow Registry setup failed with: {e}\")\n",
    "            \n",
    "    try:\n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"‚úì MLflow Experiment set to: {EXPERIMENT_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Critical: MLflow Experiment setup failed! Error: {e}\")\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_data_for_training(spark: SparkSession, table_name: str):\n",
    "    \"\"\"‡§°‡•á‡§≤‡•ç‡§ü‡§æ ‡§ü‡•á‡§¨‡§≤ ‡§∏‡•á ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§° ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ Pandas DataFrame ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§§‡§æ ‡§π‡•à‡•§\"\"\"\n",
    "    print(f\"üíæ Loading data from Delta Table: {table_name}\")\n",
    "    try:\n",
    "        # Delta Table ‡§∏‡•á Spark DataFrame ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç\n",
    "        df_spark = spark.read.format(\"delta\").table(table_name)\n",
    "        \n",
    "        # ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§ï‡•â‡§≤‡§Æ ‡§ö‡•Å‡§®‡•á‡§Ç ‡§î‡§∞ Pandas DataFrame ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç\n",
    "        df_pd = df_spark.select(*FEATURE_COLS, col(LABEL_COL)).toPandas()\n",
    "        \n",
    "        print(f\"‚úì Data loaded. Total rows: {len(df_pd)}\")\n",
    "        \n",
    "        X = df_pd[FEATURE_COLS]\n",
    "        y = df_pd[LABEL_COL]\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data from Delta: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def train_and_log_model(X, y):\n",
    "    \"\"\"\n",
    "    Cross-validation ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§ü‡•ç‡§∞‡•á‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, best parameters ‡§¢‡•Ç‡§Ç‡§¢‡§§‡§æ ‡§π‡•à,\n",
    "    ‡§Æ‡•Ä‡§ü‡•ç‡§∞‡§ø‡§ï‡•ç‡§∏ ‡§ï‡•Ä ‡§ó‡§£‡§®‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ UC ‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§ø‡§ó‡•ç‡§®‡•á‡§ö‡§∞ ‡§ï‡•á ‡§∏‡§æ‡§• MLflow ‡§Æ‡•á‡§Ç ‡§≤‡•â‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ‡§°‡•á‡§ü‡§æ ‡§∏‡•ç‡§™‡•ç‡§≤‡§ø‡§ü ‡§ï‡§∞‡•á‡§Ç\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"RandomForest_House_Price_Model_CV\") as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"üöÄ MLflow Run Started with ID: {run_id}\")\n",
    "        \n",
    "        # 2. Cross-validation setup\n",
    "        print(f\"üîç Starting GridSearchCV with {CV_FOLDS}-fold cross-validation...\")\n",
    "        print(f\"üìä Parameter Grid: {PARAM_GRID}\")\n",
    "        \n",
    "        base_model = RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=PARAM_GRID,\n",
    "            cv=CV_FOLDS,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # 3. ‡§Æ‡•â‡§°‡§≤ ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó with cross-validation\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        print(\"‚úì GridSearchCV completed successfully.\")\n",
    "        \n",
    "        # 4. Best parameters ‡§ï‡•ã ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"‚úì Best Parameters found: {best_params}\")\n",
    "        \n",
    "        for param_name, param_value in best_params.items():\n",
    "            mlflow.log_param(f\"best_{param_name}\", param_value)\n",
    "        \n",
    "        # CV score ‡§ï‡•ã ‡§≠‡•Ä ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç\n",
    "        best_cv_score = -grid_search.best_score_  # negative ‡§∏‡•á positive ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç\n",
    "        mlflow.log_metric(\"best_cv_rmse\", np.sqrt(best_cv_score))\n",
    "        print(f\"‚úì Best CV RMSE: {np.sqrt(best_cv_score):.2f}\")\n",
    "        \n",
    "        # 5. Best model ‡§ï‡•á ‡§∏‡§æ‡§• test set ‡§™‡§∞ evaluate ‡§ï‡§∞‡•á‡§Ç\n",
    "        best_model = grid_search.best_estimator_\n",
    "        predictions = best_model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        mlflow.log_metric(\"test_rmse\", rmse)\n",
    "        mlflow.log_metric(\"test_r2_score\", r2)\n",
    "        print(f\"‚úì Test Metrics Logged: RMSE={rmse:.2f}, R2={r2:.4f}\")\n",
    "        \n",
    "        # 6. ‡§Æ‡•â‡§°‡§≤ ‡§∏‡§ø‡§ó‡•ç‡§®‡•á‡§ö‡§∞ ‡§¨‡§®‡§æ‡§è‡§Ç (UC ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§®‡§ø‡§µ‡§æ‡§∞‡•ç‡§Ø)\n",
    "        model_signature = infer_signature(\n",
    "            X_train,\n",
    "            best_model.predict(X_train)\n",
    "        )\n",
    "        print(\"‚úì Model Signature created successfully.\")\n",
    "\n",
    "        # 7. Best model ‡§ï‡•ã ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç (‡§∏‡§ø‡§ó‡•ç‡§®‡•á‡§ö‡§∞ ‡§∏‡§π‡§ø‡§§)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model, \n",
    "            artifact_path=MODEL_ARTIFACT_PATH,\n",
    "            signature=model_signature,\n",
    "            registered_model_name=None \n",
    "        )\n",
    "        print(f\"‚úì Best model logged with signature to artifact path: {MODEL_ARTIFACT_PATH}\")\n",
    "        \n",
    "        return run_id\n",
    "\n",
    "# ==================== EXECUTION ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # SparkSession ‡§ï‡•ã ‡§á‡§®‡§ø‡§∂‡§ø‡§Ø‡§≤‡§æ‡§á‡§ú‡§º ‡§Ø‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç\n",
    "        spark = SparkSession.builder.appName(\"ModelTrain\").getOrCreate()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SparkSession creation failed: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    setup_mlflow_experiment()\n",
    "    \n",
    "    # ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç\n",
    "    X, y = get_data_for_training(spark, DELTA_TABLE_NAME)\n",
    "\n",
    "    if X is not None:\n",
    "        # ‡§Æ‡•â‡§°‡§≤ ‡§ü‡•ç‡§∞‡•á‡§® ‡§î‡§∞ ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç\n",
    "        training_run_id = train_and_log_model(X, y)\n",
    "        \n",
    "        if training_run_id:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"‚úÖ TRAINING & LOGGING COMPLETE! New Run ID: {training_run_id}\")\n",
    "            print(f\"‡§Ö‡§ó‡§≤‡§æ ‡§ï‡§¶‡§Æ: 'model_register.py' ‡§ï‡•ã ‡§á‡§∏ Run ID ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ö‡§≤‡§æ‡§è‡§Å‡•§\")\n",
    "            print(\"=\" * 60)\n",
    "        else:\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
