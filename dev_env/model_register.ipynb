{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ffa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ====================== CONFIGURATION ========================= #\n",
    "try:\n",
    "    EXPERIMENT_NAME = dbutils.widgets.get(\"experiment_name\")\n",
    "    print(f\"‚úì Experiment Name from widget: {EXPERIMENT_NAME}\")\n",
    "except:\n",
    "    EXPERIMENT_NAME = \"/Shared/House_Price_Prediction_Config_Runs\"\n",
    "    print(f\"‚Ñπ Using default experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "UC_CATALOG = \"workspace\"\n",
    "UC_SCHEMA = \"ml\"\n",
    "\n",
    "# =================== MODEL CONFIG METADATA ==================== #\n",
    "MODEL_CONFIG = {\n",
    "    \"xgboost\": {\n",
    "        \"model_name\": \"house_price_xgboost_uc2\",\n",
    "        \"artifact_path\": \"xgboost_model\",\n",
    "        \"param_keys\": [\n",
    "            \"n_estimators\", \"max_depth\", \"learning_rate\",\n",
    "            \"subsample\", \"colsample_bytree\"\n",
    "        ],\n",
    "        \"metric_key\": \"test_rmse\",\n",
    "        \"keywords\": [\"xgboost\", \"xgb\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ================== MODEL TYPE DETECTION ====================== #\n",
    "def detect_model_config(experiment_name: str):\n",
    "    exp_lower = experiment_name.lower()\n",
    "    for model_type, cfg in MODEL_CONFIG.items():\n",
    "        for key in cfg[\"keywords\"]:\n",
    "            if key in exp_lower:\n",
    "                full_uc_name = f\"{UC_CATALOG}.{UC_SCHEMA}.{cfg['model_name']}\"\n",
    "                print(f\"‚úì Detected model type: {model_type.upper()}\")\n",
    "                print(f\"‚úì UC Model Name: {full_uc_name}\")\n",
    "                return (\n",
    "                    full_uc_name,\n",
    "                    cfg[\"artifact_path\"],\n",
    "                    cfg[\"param_keys\"],\n",
    "                    cfg[\"metric_key\"]\n",
    "                )\n",
    "    raise ValueError(\"‚ùå No matching model config found based on experiment name!\")\n",
    "\n",
    "REGISTERED_MODEL_NAME, ARTIFACT_PATH, PARAM_KEYS, METRIC_KEY = detect_model_config(EXPERIMENT_NAME)\n",
    "TOL = 1e-6  # float tolerance\n",
    "\n",
    "# ====================== UTILITIES ====================== #\n",
    "def normalize(val):\n",
    "    try:\n",
    "        if '.' not in str(val) and str(val).isdigit():\n",
    "            return int(val)\n",
    "        return float(val)\n",
    "    except:\n",
    "        return str(val)\n",
    "\n",
    "# ================== FIND BEST RUN ====================== #\n",
    "def get_best_run(client):\n",
    "    \"\"\"\n",
    "    Find the run with the LOWEST test_rmse metric value (best performing model)\n",
    "    \"\"\"\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if not exp:\n",
    "        print(\"‚ùå Experiment not found.\")\n",
    "        return None, {}, {}\n",
    "\n",
    "    # ‚úÖ CRITICAL FIX: Order by metric ascending to get best performing run first\n",
    "    # Remove max_results limit to fetch all runs\n",
    "    runs = client.search_runs(\n",
    "        [exp.experiment_id], \n",
    "        order_by=[f\"metrics.{METRIC_KEY} ASC\"],  # ‚úÖ Changed from start_time DESC\n",
    "        max_results=1000  # Increased to ensure all runs are fetched\n",
    "    )\n",
    "    \n",
    "    if not runs:\n",
    "        print(\"‚ö† No runs found in experiment.\")\n",
    "        return None, {}, {}\n",
    "\n",
    "    best_run = None\n",
    "    best_metric = float(\"inf\")\n",
    "\n",
    "    # Iterate through all runs to find the one with minimum RMSE\n",
    "    for r in runs:\n",
    "        metric_val = r.data.metrics.get(METRIC_KEY)\n",
    "        \n",
    "        # Only consider runs that have the metric logged\n",
    "        if metric_val is not None:\n",
    "            print(f\"  üìä Run: {r.info.run_name or r.info.run_id[:8]} | {METRIC_KEY}: {metric_val:.4f}\")\n",
    "            \n",
    "            if metric_val < best_metric:\n",
    "                best_metric = metric_val\n",
    "                best_run = r\n",
    "\n",
    "    if best_run:\n",
    "        params = {k: normalize(v) for k, v in best_run.data.params.items() if k in PARAM_KEYS}\n",
    "        metrics = best_run.data.metrics\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üèÜ BEST RUN IDENTIFIED:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   Run Name: {best_run.info.run_name or 'N/A'}\")\n",
    "        print(f\"   Run ID: {best_run.info.run_id}\")\n",
    "        print(f\"   {METRIC_KEY}: {best_metric:.6f}\")\n",
    "        print(f\"   Parameters: {params}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return best_run.info.run_id, params, metrics\n",
    "    else:\n",
    "        print(\"‚ö† No valid runs with metric found.\")\n",
    "        return None, {}, {}\n",
    "\n",
    "# ================ DUPLICATE VERSION CHECK ===================== #\n",
    "def check_duplicate(client, new_params, new_metrics):\n",
    "    \"\"\"\n",
    "    Check if a model version with same parameters and metrics already exists\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mv_list = client.search_model_versions(f\"name = '{REGISTERED_MODEL_NAME}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚Ñπ No existing model versions found (this may be first registration): {e}\")\n",
    "        return None\n",
    "    \n",
    "    if not mv_list:\n",
    "        return None\n",
    "\n",
    "    new_metric_val = new_metrics.get(METRIC_KEY, None)\n",
    "    \n",
    "    for mv in mv_list:\n",
    "        try:\n",
    "            run = client.get_run(mv.run_id)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Could not fetch run {mv.run_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        old_params = {k: normalize(v) for k, v in run.data.params.items() if k in new_params}\n",
    "        old_metric_val = run.data.metrics.get(METRIC_KEY, None)\n",
    "\n",
    "        same_params = all(old_params.get(k) == new_params.get(k) for k in new_params)\n",
    "        same_metric = (\n",
    "            old_metric_val is not None and new_metric_val is not None\n",
    "            and abs(old_metric_val - new_metric_val) <= TOL\n",
    "        )\n",
    "        \n",
    "        if same_params and same_metric:\n",
    "            print(f\"\\n‚è≠Ô∏è DUPLICATE DETECTED!\")\n",
    "            print(f\"   Existing Version: {mv.version}\")\n",
    "            print(f\"   Run ID: {mv.run_id}\")\n",
    "            print(f\"   This model is already registered with same params & performance.\")\n",
    "            return mv\n",
    "            \n",
    "    return None\n",
    "\n",
    "# ================== REGISTER MODEL LOGIC ======================= #\n",
    "def register_model(client, run_id, params, metrics):\n",
    "    \"\"\"\n",
    "    Register the best model to Unity Catalog\n",
    "    \"\"\"\n",
    "    duplicate_version = check_duplicate(client, params, metrics)\n",
    "    if duplicate_version:\n",
    "        print(f\"‚úÖ Using existing registered version: {duplicate_version.version}\")\n",
    "        return duplicate_version\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/{ARTIFACT_PATH}\"\n",
    "    print(f\"\\n‚è≥ Registering new model version...\")\n",
    "    print(f\"   Model URI: {model_uri}\")\n",
    "    print(f\"   Target: {REGISTERED_MODEL_NAME}\")\n",
    "\n",
    "    try:\n",
    "        new_version = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   Model Name: {REGISTERED_MODEL_NAME}\")\n",
    "        print(f\"   Version: {new_version.version}\")\n",
    "        print(f\"   Source Run ID: {run_id}\")\n",
    "        print(f\"   {METRIC_KEY}: {metrics.get(METRIC_KEY, 'N/A')}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # üè∑Ô∏è Add helpful tags for tracking\n",
    "        client.set_model_version_tag(\n",
    "            REGISTERED_MODEL_NAME, \n",
    "            new_version.version, \n",
    "            \"source_run_id\", \n",
    "            run_id\n",
    "        )\n",
    "        client.set_model_version_tag(\n",
    "            REGISTERED_MODEL_NAME, \n",
    "            new_version.version, \n",
    "            \"experiment_name\", \n",
    "            EXPERIMENT_NAME\n",
    "        )\n",
    "        client.set_model_version_tag(\n",
    "            REGISTERED_MODEL_NAME, \n",
    "            new_version.version, \n",
    "            \"metric_rmse\", \n",
    "            str(metrics.get(METRIC_KEY, \"\"))\n",
    "        )\n",
    "        \n",
    "        # Add parameters as tags for easy reference\n",
    "        for param_key, param_val in params.items():\n",
    "            client.set_model_version_tag(\n",
    "                REGISTERED_MODEL_NAME,\n",
    "                new_version.version,\n",
    "                f\"param_{param_key}\",\n",
    "                str(param_val)\n",
    "            )\n",
    "\n",
    "        return new_version\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Registration Failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "\n",
    "# ============================ MAIN ============================ #\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üöÄ MODEL REGISTRATION - BEST RUN SELECTION (MLflow + UC)\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    print(f\"üìã Configuration:\")\n",
    "    print(f\"   Experiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"   Target Model: {REGISTERED_MODEL_NAME}\")\n",
    "    print(f\"   Metric to optimize: {METRIC_KEY} (lower is better)\")\n",
    "    print(f\"   Artifact Path: {ARTIFACT_PATH}\\n\")\n",
    "    \n",
    "    print(\"üîç Searching for best run...\")\n",
    "    run_id, params, metrics = get_best_run(client)\n",
    "\n",
    "    if run_id:\n",
    "        register_model(client, run_id, params, metrics)\n",
    "        print(\"\\n‚ú® Registration process completed successfully!\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid best run found. Exiting.\")\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
