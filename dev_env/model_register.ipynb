{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ffa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================================\n",
    "# üèÜ MODEL REGISTRATION SCRIPT (READS FROM EVALUATION RESULTS)\n",
    "# =============================================================================\n",
    "# Purpose: Register approved models from evaluation pipeline\n",
    "# Prerequisites: Run model_evaluation_final_fixed.py first\n",
    "# Fixed: Aliases iteration error completely resolved\n",
    "# =============================================================================\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import traceback\n",
    "from typing import Dict, Optional, Tuple, Any\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit, when, col\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üèÜ MODEL REGISTRATION SYSTEM (FROM EVALUATION RESULTS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ====================== CONFIGURATION ========================= #\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Unity Catalog Configuration\n",
    "        self.UC_CATALOG = \"workspace\"\n",
    "        self.UC_SCHEMA = \"ml\"\n",
    "        self.MODEL_NAME = f\"{self.UC_CATALOG}.{self.UC_SCHEMA}.house_price_xgboost_uc2\"\n",
    "        \n",
    "        # Aliases\n",
    "        self.STAGING_ALIAS = \"Staging\"\n",
    "        self.PRODUCTION_ALIAS = \"production\"\n",
    "        \n",
    "        # Delta Tables (must match evaluation script)\n",
    "        self.BEST_MODEL_METADATA_TABLE = \"workspace.default.best_model_metadata\"\n",
    "        self.EVALUATION_LOG_TABLE = \"workspace.default.model_evaluation_log\"\n",
    "        \n",
    "        # Model Configuration\n",
    "        self.ARTIFACT_PATH = \"xgboost_model\"\n",
    "        self.METRIC_KEY = \"test_rmse\"\n",
    "        self.TOL = 1e-6  # Float comparison tolerance\n",
    "        \n",
    "        # Slack Configuration\n",
    "        self.SLACK_WEBHOOK_URL = self._get_slack_webhook()\n",
    "        \n",
    "    def _get_slack_webhook(self) -> Optional[str]:\n",
    "        \"\"\"Safely retrieve Slack webhook URL\"\"\"\n",
    "        try:\n",
    "            for scope in [\"shared-scope\", \"dev-scope\"]:\n",
    "                try:\n",
    "                    webhook = dbutils.secrets.get(scope, \"SLACK_WEBHOOK_URL\")\n",
    "                    if webhook and webhook.strip():\n",
    "                        print(f\"‚úÖ Slack webhook configured from scope '{scope}'\")\n",
    "                        return webhook\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        print(\"‚ÑπÔ∏è Slack notifications disabled\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"\\nüìã CONFIGURATION:\")\n",
    "print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "print(f\"   Staging Alias: @{config.STAGING_ALIAS}\")\n",
    "print(f\"   Production Alias: @{config.PRODUCTION_ALIAS}\")\n",
    "print(f\"   Metadata Table: {config.BEST_MODEL_METADATA_TABLE}\")\n",
    "print(f\"   Log Table: {config.EVALUATION_LOG_TABLE}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# =================== SLACK NOTIFICATION HELPER ==================== #\n",
    "class SlackNotifier:\n",
    "    \"\"\"Enhanced Slack notification handler\"\"\"\n",
    "    \n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "        self.enabled = webhook_url is not None\n",
    "        \n",
    "    def send(self, message: str, level: str = \"info\") -> bool:\n",
    "        \"\"\"Send Slack notification with error handling\"\"\"\n",
    "        if not self.enabled:\n",
    "            print(f\"üì¢ [SLACK DISABLED] {message}\")\n",
    "            return False\n",
    "            \n",
    "        emoji_map = {\n",
    "            \"info\": \"‚ÑπÔ∏è\",\n",
    "            \"success\": \"‚úÖ\",\n",
    "            \"warning\": \"‚ö†Ô∏è\",\n",
    "            \"error\": \"‚ùå\"\n",
    "        }\n",
    "        \n",
    "        formatted_message = f\"{emoji_map.get(level, '‚ÑπÔ∏è')} {message}\"\n",
    "        payload = {\"text\": formatted_message}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.webhook_url, \n",
    "                json=payload,\n",
    "                timeout=5\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                print(f\"üì¢ Slack notification sent: {level}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Slack error: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Slack notification failed: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# Initialize Slack notifier\n",
    "slack = SlackNotifier(config.SLACK_WEBHOOK_URL)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ INITIALIZATION\n",
    "# =============================================================================\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"ModelRegistration\").getOrCreate()\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = MlflowClient()\n",
    "    print(\"\\n‚úÖ MLflow and Spark initialized\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization failed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üîß HELPER: GET MODEL ALIASES SAFELY\n",
    "# =============================================================================\n",
    "def get_model_aliases_safe(model_name: str, version: int) -> list:\n",
    "    \"\"\"\n",
    "    Safely get aliases for a model version using direct API call\n",
    "    Avoids iteration issues with aliases property\n",
    "    \"\"\"\n",
    "    try:\n",
    "        common_aliases = ['production', 'Staging', 'champion', 'baseline']\n",
    "        found_aliases = []\n",
    "        \n",
    "        for alias in common_aliases:\n",
    "            try:\n",
    "                alias_version = client.get_model_version_by_alias(model_name, alias)\n",
    "                if alias_version and str(alias_version.version) == str(version):\n",
    "                    found_aliases.append(alias)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return found_aliases\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìã STEP 1: READ EVALUATION RESULTS\n",
    "# =============================================================================\n",
    "def get_evaluation_results() -> Optional[Dict]:\n",
    "    \"\"\"Read latest evaluation results from Delta table\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 1: Reading Evaluation Results\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Check if table exists\n",
    "        tables = spark.catalog.listTables(\"default\")\n",
    "        table_names = [t.name for t in tables]\n",
    "        \n",
    "        if \"best_model_metadata\" not in table_names:\n",
    "            print(f\"‚ùå Table '{config.BEST_MODEL_METADATA_TABLE}' not found!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Read latest evaluation\n",
    "        df = spark.read.format(\"delta\").table(config.BEST_MODEL_METADATA_TABLE)\n",
    "        \n",
    "        if df.count() == 0:\n",
    "            print(\"‚ùå No evaluation results found in table!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Get latest evaluation (most recent timestamp)\n",
    "        latest = df.orderBy(df.evaluation_timestamp.desc()).first()\n",
    "        \n",
    "        print(f\"‚úÖ Evaluation Results Found:\")\n",
    "        print(f\"   Evaluated At: {latest.evaluation_timestamp}\")\n",
    "        print(f\"   Run ID: {latest.run_id}\")\n",
    "        print(f\"   Run Name: {latest.run_name}\")\n",
    "        print(f\"   Model URI: {latest.model_uri}\")\n",
    "        print(f\"   Metric ({latest.metric_key}): {latest.metric_value:.6f}\")\n",
    "        print(f\"   Should Register: {'YES ‚úÖ' if latest.should_register else 'NO ‚ùå'}\")\n",
    "        print(f\"   Reason: {latest.evaluation_reason}\")\n",
    "        print(f\"   Improvement: {latest.improvement_pct:.2f}%\")\n",
    "        print(f\"   Total Runs Evaluated: {latest.total_runs_evaluated}\")\n",
    "        \n",
    "        return {\n",
    "            'run_id': latest.run_id,\n",
    "            'run_name': latest.run_name,\n",
    "            'model_uri': latest.model_uri,\n",
    "            'artifact_path': latest.artifact_path,\n",
    "            'metric_key': latest.metric_key,\n",
    "            'metric_value': float(latest.metric_value),\n",
    "            'should_register': bool(latest.should_register),\n",
    "            'reason': latest.evaluation_reason,\n",
    "            'improvement_pct': float(latest.improvement_pct),\n",
    "            'total_runs': int(latest.total_runs_evaluated),\n",
    "            'evaluation_time': latest.evaluation_timestamp,\n",
    "            'params_json': latest.params_json if hasattr(latest, 'params_json') else \"{}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read evaluation results: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üîç STEP 2: CHECK FOR DUPLICATE VERSIONS (FIXED)\n",
    "# =============================================================================\n",
    "def check_duplicate(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Check if model with same run_id already exists - Fixed aliases issue\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 2: Checking for Duplicates\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        mv_list = client.search_model_versions(\n",
    "            f\"name = '{config.MODEL_NAME}'\"\n",
    "        )\n",
    "        \n",
    "        # Convert to list safely\n",
    "        versions_list = []\n",
    "        try:\n",
    "            for v in mv_list:\n",
    "                versions_list.append(v)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    if not versions_list:\n",
    "        print(\"‚ÑπÔ∏è No existing versions found (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(versions_list)} existing version(s)\")\n",
    "    \n",
    "    new_run_id = eval_results['run_id']\n",
    "    new_metric = eval_results['metric_value']\n",
    "    \n",
    "    # Check each existing version\n",
    "    for mv in versions_list:\n",
    "        try:\n",
    "            # Check if same run_id\n",
    "            if mv.run_id == new_run_id:\n",
    "                # Get aliases safely without iteration\n",
    "                version_aliases = get_model_aliases_safe(config.MODEL_NAME, mv.version)\n",
    "                aliases_str = ', '.join(version_aliases) if version_aliases else 'None'\n",
    "                \n",
    "                print(f\"\\n‚ö†Ô∏è DUPLICATE DETECTED!\")\n",
    "                print(f\"   Existing Version: v{mv.version}\")\n",
    "                print(f\"   Run ID: {mv.run_id}\")\n",
    "                print(f\"   Aliases: {aliases_str}\")\n",
    "                print(f\"\\n   ‚Üí Model already registered, skipping registration\")\n",
    "                \n",
    "                slack.send(\n",
    "                    f\"‚ö†Ô∏è Duplicate detected ‚Äî using existing version *v{mv.version}* \"\n",
    "                    f\"for `{config.MODEL_NAME}`\",\n",
    "                    level=\"warning\"\n",
    "                )\n",
    "                return mv\n",
    "            \n",
    "            # Also check metric similarity (within tolerance)\n",
    "            try:\n",
    "                run = client.get_run(mv.run_id)\n",
    "                old_metric = run.data.metrics.get(config.METRIC_KEY)\n",
    "                \n",
    "                if old_metric and abs(old_metric - new_metric) <= config.TOL:\n",
    "                    print(f\"\\n‚ö†Ô∏è Similar model found!\")\n",
    "                    print(f\"   Version: v{mv.version}\")\n",
    "                    print(f\"   Metric difference: {abs(old_metric - new_metric):.8f}\")\n",
    "                    print(f\"   (Within tolerance: {config.TOL})\")\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error checking version {mv.version}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n‚úÖ No duplicates found - proceeding with registration\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ STEP 3: REGISTER MODEL TO UNITY CATALOG\n",
    "# =============================================================================\n",
    "def register_model(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Register the approved model to Unity Catalog\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 3: Registering Model to Unity Catalog\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Check if model is approved\n",
    "    if not eval_results['should_register']:\n",
    "        print(\"‚ùå Model NOT APPROVED for registration\")\n",
    "        print(f\"   Reason: {eval_results['reason']}\")\n",
    "        print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚è≠Ô∏è Model registration skipped for `{config.MODEL_NAME}`\\n\"\n",
    "            f\"Reason: {eval_results['reason']}\",\n",
    "            level=\"warning\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate = check_duplicate(eval_results)\n",
    "    if duplicate:\n",
    "        return duplicate\n",
    "\n",
    "    # Proceed with registration\n",
    "    try:\n",
    "        print(f\"\\n‚è≥ Registering model...\")\n",
    "        print(f\"   Model URI: {eval_results['model_uri']}\")\n",
    "        print(f\"   Target: {config.MODEL_NAME}\")\n",
    "        \n",
    "        # Register the model\n",
    "        new_version = mlflow.register_model(\n",
    "            eval_results['model_uri'], \n",
    "            config.MODEL_NAME\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "        print(f\"   Version: v{new_version.version}\")\n",
    "        print(f\"   Source Run ID: {eval_results['run_id']}\")\n",
    "        print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "        print(f\"   {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\")\n",
    "        print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Send Slack notification\n",
    "        slack.send(\n",
    "            f\"‚úÖ Model *{config.MODEL_NAME}* registered as version *v{new_version.version}*\\n\"\n",
    "            f\"üìä {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\\n\"\n",
    "            f\"üìà Improvement: {eval_results['improvement_pct']:.2f}%\\n\"\n",
    "            f\"üîó Run: {eval_results['run_name']}\",\n",
    "            level=\"success\"\n",
    "        )\n",
    "        \n",
    "        return new_version\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Registration failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚ùå Model registration failed for `{config.MODEL_NAME}`: {e}\",\n",
    "            level=\"error\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üè∑Ô∏è STEP 4: SET STAGING ALIAS & ADD TAGS\n",
    "# =============================================================================\n",
    "def set_staging_alias_and_tags(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Set Staging alias and add comprehensive tags\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Setting Alias & Tags\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Set Staging alias\n",
    "        print(f\"‚è≥ Setting @{config.STAGING_ALIAS} alias for Version {version_number}\")\n",
    "        \n",
    "        client.set_registered_model_alias(\n",
    "            config.MODEL_NAME, \n",
    "            config.STAGING_ALIAS, \n",
    "            version_number\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Alias Set: Version {version_number} ‚Üí @{config.STAGING_ALIAS}\")\n",
    "        \n",
    "        # Add comprehensive tags\n",
    "        tags = {\n",
    "            \"registered_from\": \"registration_pipeline\",\n",
    "            \"evaluation_reason\": eval_results['reason'],\n",
    "            \"improvement_pct\": f\"{eval_results['improvement_pct']:.2f}\",\n",
    "            \"registration_timestamp\": datetime.now().isoformat(),\n",
    "            \"metric_rmse\": str(eval_results['metric_value']),\n",
    "            \"source_run_id\": eval_results['run_id'],\n",
    "            \"source_run_name\": eval_results['run_name'],\n",
    "            \"total_runs_evaluated\": str(eval_results['total_runs']),\n",
    "            \"artifact_path\": eval_results['artifact_path'],\n",
    "            \"evaluation_timestamp\": str(eval_results['evaluation_time'])\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüè∑Ô∏è  Adding tags to Version {version_number}:\")\n",
    "        for key, value in tags.items():\n",
    "            try:\n",
    "                client.set_model_version_tag(\n",
    "                    config.MODEL_NAME, \n",
    "                    version_number, \n",
    "                    key, \n",
    "                    value\n",
    "                )\n",
    "                print(f\"   ‚úÖ {key}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Failed to add tag {key}: {e}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ All tags added successfully\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to set alias or tags: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìù STEP 5: UPDATE EVALUATION LOG\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# üìù STEP 5: UPDATE EVALUATION LOG (FIXED)\n",
    "# =============================================================================\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "def update_evaluation_log(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Update evaluation log with registration status safely using DeltaTable\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 5: Updating Evaluation Log (FIXED)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Load Delta table\n",
    "        delta_table = DeltaTable.forName(spark, config.EVALUATION_LOG_TABLE)\n",
    "        \n",
    "        # Check and add missing columns if needed\n",
    "        existing_columns = [f.name for f in spark.table(config.EVALUATION_LOG_TABLE).schema.fields]\n",
    "        if 'promoted_to_staging' not in existing_columns:\n",
    "            print(\"‚ÑπÔ∏è Column 'promoted_to_staging' missing, adding...\")\n",
    "            spark.sql(f\"ALTER TABLE {config.EVALUATION_LOG_TABLE} ADD COLUMN promoted_to_staging BOOLEAN\")\n",
    "            print(\"‚úÖ Column 'promoted_to_staging' added\")\n",
    "\n",
    "        if 'promoted_version' not in existing_columns:\n",
    "            print(\"‚ÑπÔ∏è Column 'promoted_version' missing, adding...\")\n",
    "            spark.sql(f\"ALTER TABLE {config.EVALUATION_LOG_TABLE} ADD COLUMN promoted_version BIGINT\")\n",
    "            print(\"‚úÖ Column 'promoted_version' added\")\n",
    "        \n",
    "        # Perform safe update using DeltaTable.update()\n",
    "        delta_table.update(\n",
    "            condition = f\"new_run_id = '{eval_results['run_id']}'\",\n",
    "            set = {\n",
    "                \"promoted_to_staging\": \"true\",\n",
    "                \"promoted_version\": str(version_number)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Verification\n",
    "        verify_row = spark.read.format(\"delta\").table(config.EVALUATION_LOG_TABLE)\\\n",
    "            .filter(col(\"new_run_id\") == eval_results['run_id']).first()\n",
    "        \n",
    "        if verify_row and verify_row.promoted_to_staging:\n",
    "            print(f\"‚úÖ Evaluation log updated successfully\")\n",
    "            print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "            print(f\"   Promoted to Staging: True\")\n",
    "            print(f\"   Promoted Version: v{verify_row.promoted_version if verify_row.promoted_version else 'N/A'}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Update verification failed\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to update evaluation log: {e}\")\n",
    "        print(f\"   Error type: {type(e).__name__}\")\n",
    "        traceback.print_exc()\n",
    "        print(\"   (Non-critical error - continuing)\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìä STEP 6: DISPLAY REGISTRATION SUMMARY\n",
    "# =============================================================================\n",
    "def display_summary(eval_results: Dict, version_number: int) -> None:\n",
    "    \"\"\"Display comprehensive registration summary\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ MODEL REGISTRATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìä Source Model:\")\n",
    "    print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "    print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "    print(f\"   RMSE: {eval_results['metric_value']:.6f}\")\n",
    "    print(f\"   Rank: #1 from {eval_results['total_runs']} runs\")\n",
    "    print(f\"   Evaluated At: {eval_results['evaluation_time']}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Registered Model:\")\n",
    "    print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "    print(f\"   Version: v{version_number}\")\n",
    "    print(f\"   Alias: @{config.STAGING_ALIAS}\")\n",
    "    print(f\"   Status: ‚úÖ ACTIVE\")\n",
    "    \n",
    "    print(f\"\\nüìà Performance:\")\n",
    "    print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "    print(f\"   Reason: {eval_results['reason']}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    print(f\"   1. Test model in Staging environment\")\n",
    "    print(f\"   2. Validate performance metrics\")\n",
    "    print(f\"   3. Run A/B tests if applicable\")\n",
    "    print(f\"   4. Promote to @{config.PRODUCTION_ALIAS} if successful\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Model Access:\")\n",
    "    print(f\"   UC Path: {config.MODEL_NAME}\")\n",
    "    print(f\"   Alias: models:/{config.MODEL_NAME}@{config.STAGING_ALIAS}\")\n",
    "    print(f\"   Version: models:/{config.MODEL_NAME}/{version_number}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üé¨ MAIN EXECUTION\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main execution flow with comprehensive error handling\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ STARTING MODEL REGISTRATION PIPELINE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Read evaluation results\n",
    "        eval_results = get_evaluation_results()\n",
    "        if not eval_results:\n",
    "            print(\"\\n‚ùå REGISTRATION FAILED - No evaluation results found\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Check approval status\n",
    "        if not eval_results['should_register']:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"‚è≠Ô∏è REGISTRATION SKIPPED\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"   Model was NOT approved during evaluation\")\n",
    "            print(f\"   Reason: {eval_results['reason']}\")\n",
    "            print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "            print(f\"\\nüí° Model needs better performance to be registered\")\n",
    "            print(f\"{'='*80}\")\n",
    "            sys.exit(0)  # Exit gracefully, not an error\n",
    "        \n",
    "        # Step 2 & 3: Register model (includes duplicate check)\n",
    "        new_version = register_model(eval_results)\n",
    "        if not new_version:\n",
    "            print(\"\\n‚ùå REGISTRATION FAILED\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Step 4: Set Staging alias and add tags\n",
    "        alias_set = set_staging_alias_and_tags(new_version.version, eval_results)\n",
    "        if not alias_set:\n",
    "            print(\"\\n‚ö†Ô∏è WARNING: Model registered but alias/tags not set properly\")\n",
    "        \n",
    "        # Step 5: Update evaluation log\n",
    "        update_evaluation_log(new_version.version, eval_results)\n",
    "        \n",
    "        # Step 6: Display summary\n",
    "        display_summary(eval_results, new_version.version)\n",
    "        \n",
    "        print(\"‚úÖ Registration pipeline completed successfully!\")\n",
    "        sys.exit(0)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Process interrupted by user\")\n",
    "        slack.send(\n",
    "            f\"‚ö†Ô∏è Model registration interrupted for `{config.MODEL_NAME}`\",\n",
    "            level=\"warning\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå UNEXPECTED ERROR: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚ùå Critical error in model registration: {e}\",\n",
    "            level=\"error\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# ============================ ENTRY POINT ============================ #\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Databricks notebook source\n",
    "# =============================================================================\n",
    "# üèÜ MODEL REGISTRATION SCRIPT (READS FROM EVALUATION RESULTS)\n",
    "# =============================================================================\n",
    "# Purpose: Register approved models from evaluation pipeline\n",
    "# Prerequisites: Run model_evaluation_final_fixed.py first\n",
    "# Fixed: Aliases iteration error completely resolved\n",
    "# =============================================================================\n",
    "\n",
    "# import mlflow\n",
    "# from mlflow.tracking import MlflowClient\n",
    "# import sys\n",
    "# import os\n",
    "# import requests\n",
    "# import traceback\n",
    "# from typing import Dict, Optional, Tuple, Any\n",
    "# from datetime import datetime\n",
    "# from pyspark.sql import SparkSession\n",
    "# import pandas as pd\n",
    "# from pyspark.sql.functions import lit, when, col\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"üèÜ MODEL REGISTRATION SYSTEM (FROM EVALUATION RESULTS)\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# # ====================== CONFIGURATION ========================= #\n",
    "# class Config:\n",
    "#     \"\"\"Centralized configuration management\"\"\"\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         # Unity Catalog Configuration\n",
    "#         self.UC_CATALOG = \"workspace\"\n",
    "#         self.UC_SCHEMA = \"ml\"\n",
    "#         self.MODEL_NAME = f\"{self.UC_CATALOG}.{self.UC_SCHEMA}.house_price_xgboost_uc2\"\n",
    "        \n",
    "#         # Aliases\n",
    "#         self.STAGING_ALIAS = \"Staging\"\n",
    "#         self.PRODUCTION_ALIAS = \"production\"\n",
    "        \n",
    "#         # Delta Tables (must match evaluation script)\n",
    "#         self.BEST_MODEL_METADATA_TABLE = \"workspace.default.best_model_metadata\"\n",
    "#         self.EVALUATION_LOG_TABLE = \"workspace.default.model_evaluation_log\"\n",
    "        \n",
    "#         # Model Configuration\n",
    "#         self.ARTIFACT_PATH = \"xgboost_model\"\n",
    "#         self.METRIC_KEY = \"test_rmse\"\n",
    "#         self.TOL = 1e-6  # Float comparison tolerance\n",
    "        \n",
    "#         # Slack Configuration\n",
    "#         self.SLACK_WEBHOOK_URL = self._get_slack_webhook()\n",
    "        \n",
    "#     def _get_slack_webhook(self) -> Optional[str]:\n",
    "#         \"\"\"Safely retrieve Slack webhook URL\"\"\"\n",
    "#         try:\n",
    "#             for scope in [\"shared-scope\", \"dev-scope\"]:\n",
    "#                 try:\n",
    "#                     webhook = dbutils.secrets.get(scope, \"SLACK_WEBHOOK_URL\")\n",
    "#                     if webhook and webhook.strip():\n",
    "#                         print(f\"‚úÖ Slack webhook configured from scope '{scope}'\")\n",
    "#                         return webhook\n",
    "#                 except Exception:\n",
    "#                     continue\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "#         print(\"‚ÑπÔ∏è Slack notifications disabled\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # Initialize configuration\n",
    "# config = Config()\n",
    "\n",
    "# print(\"\\nüìã CONFIGURATION:\")\n",
    "# print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "# print(f\"   Staging Alias: @{config.STAGING_ALIAS}\")\n",
    "# print(f\"   Production Alias: @{config.PRODUCTION_ALIAS}\")\n",
    "# print(f\"   Metadata Table: {config.BEST_MODEL_METADATA_TABLE}\")\n",
    "# print(f\"   Log Table: {config.EVALUATION_LOG_TABLE}\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# # =================== SLACK NOTIFICATION HELPER ==================== #\n",
    "# class SlackNotifier:\n",
    "#     \"\"\"Enhanced Slack notification handler\"\"\"\n",
    "    \n",
    "#     def __init__(self, webhook_url: Optional[str]):\n",
    "#         self.webhook_url = webhook_url\n",
    "#         self.enabled = webhook_url is not None\n",
    "        \n",
    "#     def send(self, message: str, level: str = \"info\") -> bool:\n",
    "#         \"\"\"Send Slack notification with error handling\"\"\"\n",
    "#         if not self.enabled:\n",
    "#             print(f\"üì¢ [SLACK DISABLED] {message}\")\n",
    "#             return False\n",
    "            \n",
    "#         emoji_map = {\n",
    "#             \"info\": \"‚ÑπÔ∏è\",\n",
    "#             \"success\": \"‚úÖ\",\n",
    "#             \"warning\": \"‚ö†Ô∏è\",\n",
    "#             \"error\": \"‚ùå\"\n",
    "#         }\n",
    "        \n",
    "#         formatted_message = f\"{emoji_map.get(level, '‚ÑπÔ∏è')} {message}\"\n",
    "#         payload = {\"text\": formatted_message}\n",
    "        \n",
    "#         try:\n",
    "#             response = requests.post(\n",
    "#                 self.webhook_url, \n",
    "#                 json=payload,\n",
    "#                 timeout=5\n",
    "#             )\n",
    "#             response.raise_for_status()  # ‚úÖ ensure error is raised if not 200\n",
    "#             print(f\"üì¢ Slack notification sent: {level}\")\n",
    "#             return True\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ùå Slack notification failed: {e}\")\n",
    "#             return False\n",
    "\n",
    "\n",
    "# # Initialize Slack notifier\n",
    "# slack = SlackNotifier(config.SLACK_WEBHOOK_URL)\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # ‚úÖ INITIALIZATION\n",
    "# # =============================================================================\n",
    "# try:\n",
    "#     spark = SparkSession.builder.appName(\"ModelRegistration\").getOrCreate()\n",
    "#     mlflow.set_tracking_uri(\"databricks\")\n",
    "#     mlflow.set_registry_uri(\"databricks-uc\")\n",
    "#     client = MlflowClient()\n",
    "#     print(\"\\n‚úÖ MLflow and Spark initialized\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Initialization failed: {e}\")\n",
    "#     traceback.print_exc()\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üîß HELPER: GET MODEL ALIASES SAFELY\n",
    "# # =============================================================================\n",
    "# def get_model_aliases_safe(model_name: str, version: int) -> list:\n",
    "#     \"\"\"\n",
    "#     Safely get aliases for a model version using direct API call\n",
    "#     Avoids iteration issues with aliases property\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         common_aliases = ['production', 'Staging', 'champion', 'baseline']\n",
    "#         found_aliases = []\n",
    "        \n",
    "#         for alias in common_aliases:\n",
    "#             try:\n",
    "#                 alias_version = client.get_model_version_by_alias(model_name, alias)\n",
    "#                 if alias_version and str(alias_version.version) == str(version):\n",
    "#                     found_aliases.append(alias)\n",
    "#             except:\n",
    "#                 continue\n",
    "        \n",
    "#         return found_aliases\n",
    "#     except Exception:\n",
    "#         return []\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üìã STEP 1: READ EVALUATION RESULTS\n",
    "# # =============================================================================\n",
    "# def get_evaluation_results() -> Optional[Dict]:\n",
    "#     \"\"\"Read latest evaluation results from Delta table\"\"\"\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(\"üìã STEP 1: Reading Evaluation Results\")\n",
    "#     print(f\"{'='*70}\")\n",
    "\n",
    "#     try:\n",
    "#         # Check if table exists\n",
    "#         tables = spark.catalog.listTables(\"default\")\n",
    "#         table_names = [t.name for t in tables]\n",
    "        \n",
    "#         if \"best_model_metadata\" not in table_names:\n",
    "#             print(f\"‚ùå Table '{config.BEST_MODEL_METADATA_TABLE}' not found!\")\n",
    "#             print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "#             return None\n",
    "        \n",
    "#         # Read latest evaluation\n",
    "#         df = spark.read.format(\"delta\").table(config.BEST_MODEL_METADATA_TABLE)\n",
    "        \n",
    "#         if df.count() == 0:\n",
    "#             print(\"‚ùå No evaluation results found in table!\")\n",
    "#             print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "#             return None\n",
    "        \n",
    "#         # Get latest evaluation (most recent timestamp)\n",
    "#         latest = df.orderBy(df.evaluation_timestamp.desc()).first()\n",
    "        \n",
    "#         print(f\"‚úÖ Evaluation Results Found:\")\n",
    "#         print(f\"   Evaluated At: {latest.evaluation_timestamp}\")\n",
    "#         print(f\"   Run ID: {latest.run_id}\")\n",
    "#         print(f\"   Run Name: {latest.run_name}\")\n",
    "#         print(f\"   Model URI: {latest.model_uri}\")\n",
    "#         print(f\"   Metric ({latest.metric_key}): {latest.metric_value:.6f}\")\n",
    "#         print(f\"   Should Register: {'YES ‚úÖ' if latest.should_register else 'NO ‚ùå'}\")\n",
    "#         print(f\"   Reason: {latest.evaluation_reason}\")\n",
    "#         print(f\"   Improvement: {latest.improvement_pct:.2f}%\")\n",
    "#         print(f\"   Total Runs Evaluated: {latest.total_runs_evaluated}\")\n",
    "        \n",
    "#         return {\n",
    "#             'run_id': latest.run_id,\n",
    "#             'run_name': latest.run_name,\n",
    "#             'model_uri': latest.model_uri,\n",
    "#             'artifact_path': latest.artifact_path,\n",
    "#             'metric_key': latest.metric_key,\n",
    "#             'metric_value': float(latest.metric_value),\n",
    "#             'should_register': bool(latest.should_register),\n",
    "#             'reason': latest.evaluation_reason,\n",
    "#             'improvement_pct': float(latest.improvement_pct),\n",
    "#             'total_runs': int(latest.total_runs_evaluated),\n",
    "#             'evaluation_time': latest.evaluation_timestamp,\n",
    "#             'params_json': latest.params_json if hasattr(latest, 'params_json') else \"{}\"\n",
    "#         }\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Failed to read evaluation results: {e}\")\n",
    "#         traceback.print_exc()\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üîç STEP 2: CHECK FOR DUPLICATE VERSIONS (FIXED)\n",
    "# # =============================================================================\n",
    "# def check_duplicate(eval_results: Dict) -> Optional[Any]:\n",
    "#     \"\"\"Check if model with same run_id already exists - Fixed aliases issue\"\"\"\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(\"üìã STEP 2: Checking for Duplicates\")\n",
    "#     print(f\"{'='*70}\")\n",
    "\n",
    "#     try:\n",
    "#         mv_list = client.search_model_versions(\n",
    "#             f\"name = '{config.MODEL_NAME}'\"\n",
    "#         )\n",
    "        \n",
    "#         # Convert to list safely\n",
    "#         versions_list = []\n",
    "#         try:\n",
    "#             for v in mv_list:\n",
    "#                 versions_list.append(v)\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "#             return None\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "#         return None\n",
    "    \n",
    "#     if not versions_list:\n",
    "#         print(\"‚ÑπÔ∏è No existing versions found (first registration)\")\n",
    "#         return None\n",
    "    \n",
    "#     print(f\"‚úÖ Found {len(versions_list)} existing version(s)\")\n",
    "    \n",
    "#     new_run_id = eval_results['run_id']\n",
    "#     new_metric = eval_results['metric_value']\n",
    "    \n",
    "#     # Check each existing version\n",
    "#     for mv in versions_list:\n",
    "#         try:\n",
    "#             # Check if same run_id\n",
    "#             if mv.run_id == new_run_id:\n",
    "#                 # Get aliases safely without iteration\n",
    "#                 version_aliases = get_model_aliases_safe(config.MODEL_NAME, mv.version)\n",
    "#                 aliases_str = ', '.join(version_aliases) if version_aliases else 'None'\n",
    "                \n",
    "#                 print(f\"\\n‚ö†Ô∏è DUPLICATE DETECTED!\")\n",
    "#                 print(f\"   Existing Version: v{mv.version}\")\n",
    "#                 print(f\"   Run ID: {mv.run_id}\")\n",
    "#                 print(f\"   Aliases: {aliases_str}\")\n",
    "#                 print(f\"\\n   ‚Üí Model already registered, skipping registration\")\n",
    "                \n",
    "#                 slack.send(\n",
    "#                     f\"‚ö†Ô∏è Duplicate detected ‚Äî using existing version *v{mv.version}* \"\n",
    "#                     f\"for `{config.MODEL_NAME}`\",\n",
    "#                     level=\"warning\"\n",
    "#                 )\n",
    "#                 return mv\n",
    "            \n",
    "#             # Also check metric similarity (within tolerance)\n",
    "#             try:\n",
    "#                 run = client.get_run(mv.run_id)\n",
    "#                 old_metric = run.data.metrics.get(config.METRIC_KEY)\n",
    "                \n",
    "#                 if old_metric and abs(old_metric - new_metric) <= config.TOL:\n",
    "#                     print(f\"\\n‚ö†Ô∏è Similar model found!\")\n",
    "#                     print(f\"   Version: v{mv.version}\")\n",
    "#                     print(f\"   Metric difference: {abs(old_metric - new_metric):.8f}\")\n",
    "#                     print(f\"   (Within tolerance: {config.TOL})\")\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö†Ô∏è Error checking version {mv.version}: {e}\")\n",
    "#             continue\n",
    "    \n",
    "#     print(\"\\n‚úÖ No duplicates found - proceeding with registration\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üöÄ STEP 3: REGISTER MODEL TO UNITY CATALOG\n",
    "# # =============================================================================\n",
    "# def register_model(eval_results: Dict) -> Optional[Any]:\n",
    "#     \"\"\"Register the approved model to Unity Catalog\"\"\"\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(\"üìã STEP 3: Registering Model to Unity Catalog\")\n",
    "#     print(f\"{'='*70}\")\n",
    "\n",
    "#     # Check if model is approved\n",
    "#     if not eval_results['should_register']:\n",
    "#         print(\"‚ùå Model NOT APPROVED for registration\")\n",
    "#         print(f\"   Reason: {eval_results['reason']}\")\n",
    "#         print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "        \n",
    "#         slack.send(\n",
    "#             f\"‚è≠Ô∏è Model registration skipped for `{config.MODEL_NAME}`\\n\"\n",
    "#             f\"Reason: {eval_results['reason']}\",\n",
    "#             level=\"warning\"\n",
    "#         )\n",
    "#         return None\n",
    "\n",
    "#     # Check for duplicates\n",
    "#     duplicate = check_duplicate(eval_results)\n",
    "#     if duplicate:\n",
    "#         return duplicate\n",
    "\n",
    "#     # Proceed with registration\n",
    "#     try:\n",
    "#         print(f\"\\n‚è≥ Registering model...\")\n",
    "#         print(f\"   Model URI: {eval_results['model_uri']}\")\n",
    "#         print(f\"   Target: {config.MODEL_NAME}\")\n",
    "        \n",
    "#         # Register the model\n",
    "#         new_version = mlflow.register_model(\n",
    "#             eval_results['model_uri'], \n",
    "#             config.MODEL_NAME\n",
    "#         )\n",
    "        \n",
    "#         print(f\"\\n{'='*70}\")\n",
    "#         print(\"‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "#         print(f\"{'='*70}\")\n",
    "#         print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "#         print(f\"   Version: v{new_version.version}\")\n",
    "#         print(f\"   Source Run ID: {eval_results['run_id']}\")\n",
    "#         print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "#         print(f\"   {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\")\n",
    "#         print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "#         print(f\"{'='*70}\\n\")\n",
    "        \n",
    "#         # Send Slack notification\n",
    "#         slack.send(\n",
    "#             f\"‚úÖ Model *{config.MODEL_NAME}* registered as version *v{new_version.version}*\\n\"\n",
    "#             f\"üìä {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\\n\"\n",
    "#             f\"üìà Improvement: {eval_results['improvement_pct']:.2f}%\\n\"\n",
    "#             f\"üîó Run: {eval_results['run_name']}\",\n",
    "#             level=\"success\"\n",
    "#         )\n",
    "        \n",
    "#         return new_version\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Registration failed: {e}\")\n",
    "#         traceback.print_exc()\n",
    "        \n",
    "#         slack.send(\n",
    "#             f\"‚ùå Model registration failed for `{config.MODEL_NAME}`: {e}\",\n",
    "#             level=\"error\"\n",
    "#         )\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üè∑Ô∏è STEP 4: SET STAGING ALIAS & ADD TAGS\n",
    "# # =============================================================================\n",
    "# def set_staging_alias_and_tags(version_number: int, eval_results: Dict) -> bool:\n",
    "#     \"\"\"Set Staging alias and add comprehensive tags\"\"\"\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(\"üìã STEP 4: Setting Alias & Tags\")\n",
    "#     print(f\"{'='*70}\")\n",
    "\n",
    "#     try:\n",
    "#         # Set Staging alias\n",
    "#         print(f\"‚è≥ Setting @{config.STAGING_ALIAS} alias for Version {version_number}\")\n",
    "        \n",
    "#         client.set_registered_model_alias(\n",
    "#             config.MODEL_NAME, \n",
    "#             config.STAGING_ALIAS, \n",
    "#             version_number\n",
    "#         )\n",
    "        \n",
    "#         print(f\"‚úÖ Alias Set: Version {version_number} ‚Üí @{config.STAGING_ALIAS}\")\n",
    "        \n",
    "#         # Add comprehensive tags\n",
    "#         tags = {\n",
    "#             \"registered_from\": \"registration_pipeline\",\n",
    "#             \"evaluation_reason\": eval_results['reason'],\n",
    "#             \"improvement_pct\": f\"{eval_results['improvement_pct']:.2f}\",\n",
    "#             \"registration_timestamp\": datetime.now().isoformat(),\n",
    "#             \"metric_rmse\": str(eval_results['metric_value']),\n",
    "#             \"source_run_id\": eval_results['run_id'],\n",
    "#             \"source_run_name\": eval_results['run_name'],\n",
    "#             \"total_runs_evaluated\": str(eval_results['total_runs']),\n",
    "#             \"artifact_path\": eval_results['artifact_path'],\n",
    "#             \"evaluation_timestamp\": str(eval_results['evaluation_time'])\n",
    "#         }\n",
    "        \n",
    "#         print(f\"\\nüè∑Ô∏è  Adding tags to Version {version_number}:\")\n",
    "#         for key, value in tags.items():\n",
    "#             try:\n",
    "#                 client.set_model_version_tag(\n",
    "#                     config.MODEL_NAME, \n",
    "#                     version_number, \n",
    "#                     key, \n",
    "#                     value\n",
    "#                 )\n",
    "#                 print(f\"   ‚úÖ {key}: {value}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"   ‚ö†Ô∏è Failed to add tag {key}: {e}\")\n",
    "        \n",
    "#         print(f\"\\n‚úÖ All tags added successfully\")\n",
    "#         return True\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Failed to set alias or tags: {e}\")\n",
    "#         traceback.print_exc()\n",
    "#         return False\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üìù STEP 5: UPDATE EVALUATION LOG (FIXED)\n",
    "# # =============================================================================\n",
    "# from delta.tables import DeltaTable\n",
    "\n",
    "# def update_evaluation_log(version_number: int, eval_results: Dict) -> bool:\n",
    "#     \"\"\"Update evaluation log with registration status safely using DeltaTable\"\"\"\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(\"üìã STEP 5: Updating Evaluation Log (FIXED)\")\n",
    "#     print(f\"{'='*70}\")\n",
    "\n",
    "#     try:\n",
    "#         # Load Delta table\n",
    "#         delta_table = DeltaTable.forName(spark, config.EVALUATION_LOG_TABLE)\n",
    "        \n",
    "#         # Check and add missing columns if needed\n",
    "#         existing_columns = [f.name for f in spark.table(config.EVALUATION_LOG_TABLE).schema.fields]\n",
    "#         if 'promoted_to_staging' not in existing_columns:\n",
    "#             print(\"‚ÑπÔ∏è Column 'promoted_to_staging' missing, adding...\")\n",
    "#             spark.sql(f\"ALTER TABLE {config.EVALUATION_LOG_TABLE} ADD COLUMN promoted_to_staging BOOLEAN\")\n",
    "#             print(\"‚úÖ Column 'promoted_to_staging' added\")\n",
    "\n",
    "#         if 'promoted_version' not in existing_columns:\n",
    "#             print(\"‚ÑπÔ∏è Column 'promoted_version' missing, adding...\")\n",
    "#             spark.sql(f\"ALTER TABLE {config.EVALUATION_LOG_TABLE} ADD COLUMN promoted_version BIGINT\")\n",
    "#             print(\"‚úÖ Column 'promoted_version' added\")\n",
    "        \n",
    "#         # Perform safe update using DeltaTable.update()\n",
    "#         delta_table.update(\n",
    "#             condition = f\"new_run_id = '{eval_results['run_id']}'\",\n",
    "#             set = {\n",
    "#                 \"promoted_to_staging\": True,          # <-- FIXED\n",
    "#                 \"promoted_version\": version_number    # <-- FIXED\n",
    "#             }\n",
    "#         )\n",
    "        \n",
    "#         # Verification\n",
    "#         verify_row = spark.read.format(\"delta\").table(config.EVALUATION_LOG_TABLE)\\\n",
    "#             .filter(col(\"new_run_id\") == eval_results['run_id']).first()\n",
    "        \n",
    "#         if verify_row and verify_row.promoted_to_staging:\n",
    "#             print(f\"‚úÖ Evaluation log updated successfully\")\n",
    "#             print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "#             print(f\"   Promoted to Staging: True\")\n",
    "#             print(f\"   Promoted Version: v{verify_row.promoted_version if verify_row.promoted_version else 'N/A'}\")\n",
    "#             return True\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è Update verification failed\")\n",
    "#             return False\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Failed to update evaluation log: {e}\")\n",
    "#         print(f\"   Error type: {type(e).__name__}\")\n",
    "#         traceback.print_exc()\n",
    "#         print(\"   (Non-critical error - continuing)\")\n",
    "#         return False\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üìä STEP 6: DISPLAY REGISTRATION SUMMARY\n",
    "# # =============================================================================\n",
    "# def display_summary(eval_results: Dict, version_number: int) -> None:\n",
    "#     \"\"\"Display comprehensive registration summary\"\"\"\n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(\"‚úÖ MODEL REGISTRATION COMPLETE\")\n",
    "#     print(f\"{'='*80}\")\n",
    "    \n",
    "#     print(f\"\\nüìä Source Model:\")\n",
    "#     print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "#     print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "#     print(f\"   RMSE: {eval_results['metric_value']:.6f}\")\n",
    "#     print(f\"   Rank: #1 from {eval_results['total_runs']} runs\")\n",
    "#     print(f\"   Evaluated At: {eval_results['evaluation_time']}\")\n",
    "    \n",
    "#     print(f\"\\nüèÜ Registered Model:\")\n",
    "#     print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "#     print(f\"   Version: v{version_number}\")\n",
    "#     print(f\"   Alias: @{config.STAGING_ALIAS}\")\n",
    "#     print(f\"   Status: ‚úÖ ACTIVE\")\n",
    "    \n",
    "#     print(f\"\\nüìà Performance:\")\n",
    "#     print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "#     print(f\"   Reason: {eval_results['reason']}\")\n",
    "    \n",
    "#     print(f\"\\nüéØ Next Steps:\")\n",
    "#     print(f\"   1. Test model in Staging environment\")\n",
    "#     print(f\"   2. Validate performance metrics\")\n",
    "#     print(f\"   3. Run A/B tests if applicable\")\n",
    "#     print(f\"   4. Promote to @{config.PRODUCTION_ALIAS} if successful\")\n",
    "    \n",
    "#     print(f\"\\nüì¶ Model Access:\")\n",
    "#     print(f\"   UC Path: {config.MODEL_NAME}\")\n",
    "#     print(f\"   Alias: models:/{config.MODEL_NAME}@{config.STAGING_ALIAS}\")\n",
    "#     print(f\"   Version: models:/{config.MODEL_NAME}/{version_number}\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # üé¨ MAIN EXECUTION\n",
    "# # =============================================================================\n",
    "# def main():\n",
    "#     \"\"\"Main execution flow with comprehensive error handling\"\"\"\n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(\"üöÄ STARTING MODEL REGISTRATION PIPELINE\")\n",
    "#     print(f\"{'='*80}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Step 1: Read evaluation results\n",
    "#         eval_results = get_evaluation_results()\n",
    "#         if not eval_results:\n",
    "#             print(\"\\n‚ùå REGISTRATION FAILED - No evaluation results found\")\n",
    "#             print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "#             sys.exit(1)\n",
    "        \n",
    "#         # Check approval status\n",
    "#         if not eval_results['should_register']:\n",
    "#             print(f\"\\n{'='*80}\")\n",
    "#             print(\"‚è≠Ô∏è REGISTRATION SKIPPED\")\n",
    "#             print(f\"{'='*80}\")\n",
    "#             print(f\"   Model was NOT approved during evaluation\")\n",
    "#             print(f\"   Reason: {eval_results['reason']}\")\n",
    "#             print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "#             print(f\"\\nüí° Model needs better performance to be registered\")\n",
    "#             print(f\"{'='*80}\")\n",
    "#             sys.exit(0)  # Exit gracefully, not an error\n",
    "        \n",
    "#         # Step 2 & 3: Register model (includes duplicate check)\n",
    "#         new_version = register_model(eval_results)\n",
    "#         if not new_version:\n",
    "#             print(\"\\n‚ùå REGISTRATION FAILED\")\n",
    "#             sys.exit(1)\n",
    "        \n",
    "#         # Step 4: Set Staging alias and add tags\n",
    "#         alias_set = set_staging_alias_and_tags(new_version.version, eval_results)\n",
    "#         if not alias_set:\n",
    "#             print(\"\\n‚ö†Ô∏è WARNING: Model registered but alias/tags not set properly\")\n",
    "        \n",
    "#         # Step 5: Update evaluation log\n",
    "#         update_evaluation_log(new_version.version, eval_results)\n",
    "        \n",
    "#         # Step 6: Display summary\n",
    "#         display_summary(eval_results, new_version.version)\n",
    "        \n",
    "#         print(\"‚úÖ Registration pipeline completed successfully!\")\n",
    "#         sys.exit(0)\n",
    "        \n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"\\n\\n‚ö†Ô∏è Process interrupted by user\")\n",
    "#         slack.send(\n",
    "#             f\"‚ö†Ô∏è Model registration interrupted for `{config.MODEL_NAME}`\",\n",
    "#             level=\"warning\"\n",
    "#         )\n",
    "#         sys.exit(1)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n‚ùå UNEXPECTED ERROR: {e}\")\n",
    "#         traceback.print_exc()\n",
    "        \n",
    "#         slack.send(\n",
    "#             f\"‚ùå Critical error in model registration: {e}\",\n",
    "#             level=\"error\"\n",
    "#         )\n",
    "#         sys.exit(1)\n",
    "\n",
    "\n",
    "# # ============================ ENTRY POINT ============================ #\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
