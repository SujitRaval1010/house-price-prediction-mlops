{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ffa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================================\n",
    "# üèÜ MODEL REGISTRATION SCRIPT (READS FROM EVALUATION RESULTS)\n",
    "# =============================================================================\n",
    "# Purpose: Register approved models from evaluation pipeline\n",
    "# Prerequisites: Run model_evaluation_final_fixed.py first\n",
    "# Fixed: Aliases iteration error completely resolved\n",
    "# =============================================================================\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import traceback\n",
    "from typing import Dict, Optional, Tuple, Any\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üèÜ MODEL REGISTRATION SYSTEM (FROM EVALUATION RESULTS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ====================== CONFIGURATION ========================= #\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Unity Catalog Configuration\n",
    "        self.UC_CATALOG = \"workspace\"\n",
    "        self.UC_SCHEMA = \"ml\"\n",
    "        self.MODEL_NAME = f\"{self.UC_CATALOG}.{self.UC_SCHEMA}.house_price_xgboost_uc2\"\n",
    "        \n",
    "        # Aliases\n",
    "        self.STAGING_ALIAS = \"Staging\"\n",
    "        self.PRODUCTION_ALIAS = \"production\"\n",
    "        \n",
    "        # Delta Tables (must match evaluation script)\n",
    "        self.BEST_MODEL_METADATA_TABLE = \"workspace.default.best_model_metadata\"\n",
    "        self.EVALUATION_LOG_TABLE = \"workspace.default.model_evaluation_log\"\n",
    "        \n",
    "        # Model Configuration\n",
    "        self.ARTIFACT_PATH = \"xgboost_model\"\n",
    "        self.METRIC_KEY = \"test_rmse\"\n",
    "        self.TOL = 1e-6  # Float comparison tolerance\n",
    "        \n",
    "        # Slack Configuration\n",
    "        self.SLACK_WEBHOOK_URL = self._get_slack_webhook()\n",
    "        \n",
    "    def _get_slack_webhook(self) -> Optional[str]:\n",
    "        \"\"\"Safely retrieve Slack webhook URL\"\"\"\n",
    "        try:\n",
    "            for scope in [\"shared-scope\", \"dev-scope\"]:\n",
    "                try:\n",
    "                    webhook = dbutils.secrets.get(scope, \"SLACK_WEBHOOK_URL\")\n",
    "                    if webhook and webhook.strip():\n",
    "                        print(f\"‚úÖ Slack webhook configured from scope '{scope}'\")\n",
    "                        return webhook\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        print(\"‚ÑπÔ∏è Slack notifications disabled\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"\\nüìã CONFIGURATION:\")\n",
    "print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "print(f\"   Staging Alias: @{config.STAGING_ALIAS}\")\n",
    "print(f\"   Production Alias: @{config.PRODUCTION_ALIAS}\")\n",
    "print(f\"   Metadata Table: {config.BEST_MODEL_METADATA_TABLE}\")\n",
    "print(f\"   Log Table: {config.EVALUATION_LOG_TABLE}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# =================== SLACK NOTIFICATION HELPER ==================== #\n",
    "class SlackNotifier:\n",
    "    \"\"\"Enhanced Slack notification handler\"\"\"\n",
    "    \n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "        self.enabled = webhook_url is not None\n",
    "        \n",
    "    def send(self, message: str, level: str = \"info\") -> bool:\n",
    "        \"\"\"Send Slack notification with error handling\"\"\"\n",
    "        if not self.enabled:\n",
    "            print(f\"üì¢ [SLACK DISABLED] {message}\")\n",
    "            return False\n",
    "            \n",
    "        emoji_map = {\n",
    "            \"info\": \"‚ÑπÔ∏è\",\n",
    "            \"success\": \"‚úÖ\",\n",
    "            \"warning\": \"‚ö†Ô∏è\",\n",
    "            \"error\": \"‚ùå\"\n",
    "        }\n",
    "        \n",
    "        formatted_message = f\"{emoji_map.get(level, '‚ÑπÔ∏è')} {message}\"\n",
    "        payload = {\"text\": formatted_message}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.webhook_url, \n",
    "                json=payload,\n",
    "                timeout=5\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                print(f\"üì¢ Slack notification sent: {level}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Slack error: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Slack notification failed: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# Initialize Slack notifier\n",
    "slack = SlackNotifier(config.SLACK_WEBHOOK_URL)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ INITIALIZATION\n",
    "# =============================================================================\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"ModelRegistration\").getOrCreate()\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = MlflowClient()\n",
    "    print(\"\\n‚úÖ MLflow and Spark initialized\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization failed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üîß HELPER: GET MODEL ALIASES SAFELY\n",
    "# =============================================================================\n",
    "def get_model_aliases_safe(model_name: str, version: int) -> list:\n",
    "    \"\"\"\n",
    "    Safely get aliases for a model version using direct API call\n",
    "    Avoids iteration issues with aliases property\n",
    "    \"\"\"\n",
    "    try:\n",
    "        common_aliases = ['production', 'Staging', 'champion', 'baseline']\n",
    "        found_aliases = []\n",
    "        \n",
    "        for alias in common_aliases:\n",
    "            try:\n",
    "                alias_version = client.get_model_version_by_alias(model_name, alias)\n",
    "                if alias_version and str(alias_version.version) == str(version):\n",
    "                    found_aliases.append(alias)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return found_aliases\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìã STEP 1: READ EVALUATION RESULTS\n",
    "# =============================================================================\n",
    "def get_evaluation_results() -> Optional[Dict]:\n",
    "    \"\"\"Read latest evaluation results from Delta table\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 1: Reading Evaluation Results\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Check if table exists\n",
    "        tables = spark.catalog.listTables(\"default\")\n",
    "        table_names = [t.name for t in tables]\n",
    "        \n",
    "        if \"best_model_metadata\" not in table_names:\n",
    "            print(f\"‚ùå Table '{config.BEST_MODEL_METADATA_TABLE}' not found!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Read latest evaluation\n",
    "        df = spark.read.format(\"delta\").table(config.BEST_MODEL_METADATA_TABLE)\n",
    "        \n",
    "        if df.count() == 0:\n",
    "            print(\"‚ùå No evaluation results found in table!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Get latest evaluation (most recent timestamp)\n",
    "        latest = df.orderBy(df.evaluation_timestamp.desc()).first()\n",
    "        \n",
    "        print(f\"‚úÖ Evaluation Results Found:\")\n",
    "        print(f\"   Evaluated At: {latest.evaluation_timestamp}\")\n",
    "        print(f\"   Run ID: {latest.run_id}\")\n",
    "        print(f\"   Run Name: {latest.run_name}\")\n",
    "        print(f\"   Model URI: {latest.model_uri}\")\n",
    "        print(f\"   Metric ({latest.metric_key}): {latest.metric_value:.6f}\")\n",
    "        print(f\"   Should Register: {'YES ‚úÖ' if latest.should_register else 'NO ‚ùå'}\")\n",
    "        print(f\"   Reason: {latest.evaluation_reason}\")\n",
    "        print(f\"   Improvement: {latest.improvement_pct:.2f}%\")\n",
    "        print(f\"   Total Runs Evaluated: {latest.total_runs_evaluated}\")\n",
    "        \n",
    "        return {\n",
    "            'run_id': latest.run_id,\n",
    "            'run_name': latest.run_name,\n",
    "            'model_uri': latest.model_uri,\n",
    "            'artifact_path': latest.artifact_path,\n",
    "            'metric_key': latest.metric_key,\n",
    "            'metric_value': float(latest.metric_value),\n",
    "            'should_register': bool(latest.should_register),\n",
    "            'reason': latest.evaluation_reason,\n",
    "            'improvement_pct': float(latest.improvement_pct),\n",
    "            'total_runs': int(latest.total_runs_evaluated),\n",
    "            'evaluation_time': latest.evaluation_timestamp,\n",
    "            'params_json': latest.params_json if hasattr(latest, 'params_json') else \"{}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read evaluation results: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üîç STEP 2: CHECK FOR DUPLICATE VERSIONS (FIXED)\n",
    "# =============================================================================\n",
    "def check_duplicate(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Check if model with same run_id already exists - Fixed aliases issue\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 2: Checking for Duplicates\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        mv_list = client.search_model_versions(\n",
    "            f\"name = '{config.MODEL_NAME}'\"\n",
    "        )\n",
    "        \n",
    "        # Convert to list safely\n",
    "        versions_list = []\n",
    "        try:\n",
    "            for v in mv_list:\n",
    "                versions_list.append(v)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    if not versions_list:\n",
    "        print(\"‚ÑπÔ∏è No existing versions found (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(versions_list)} existing version(s)\")\n",
    "    \n",
    "    new_run_id = eval_results['run_id']\n",
    "    new_metric = eval_results['metric_value']\n",
    "    \n",
    "    # Check each existing version\n",
    "    for mv in versions_list:\n",
    "        try:\n",
    "            # Check if same run_id\n",
    "            if mv.run_id == new_run_id:\n",
    "                # Get aliases safely without iteration\n",
    "                version_aliases = get_model_aliases_safe(config.MODEL_NAME, mv.version)\n",
    "                aliases_str = ', '.join(version_aliases) if version_aliases else 'None'\n",
    "                \n",
    "                print(f\"\\n‚ö†Ô∏è DUPLICATE DETECTED!\")\n",
    "                print(f\"   Existing Version: v{mv.version}\")\n",
    "                print(f\"   Run ID: {mv.run_id}\")\n",
    "                print(f\"   Aliases: {aliases_str}\")\n",
    "                print(f\"\\n   ‚Üí Model already registered, skipping registration\")\n",
    "                \n",
    "                slack.send(\n",
    "                    f\"‚ö†Ô∏è Duplicate detected ‚Äî using existing version *v{mv.version}* \"\n",
    "                    f\"for `{config.MODEL_NAME}`\",\n",
    "                    level=\"warning\"\n",
    "                )\n",
    "                return mv\n",
    "            \n",
    "            # Also check metric similarity (within tolerance)\n",
    "            try:\n",
    "                run = client.get_run(mv.run_id)\n",
    "                old_metric = run.data.metrics.get(config.METRIC_KEY)\n",
    "                \n",
    "                if old_metric and abs(old_metric - new_metric) <= config.TOL:\n",
    "                    print(f\"\\n‚ö†Ô∏è Similar model found!\")\n",
    "                    print(f\"   Version: v{mv.version}\")\n",
    "                    print(f\"   Metric difference: {abs(old_metric - new_metric):.8f}\")\n",
    "                    print(f\"   (Within tolerance: {config.TOL})\")\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error checking version {mv.version}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n‚úÖ No duplicates found - proceeding with registration\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ STEP 3: REGISTER MODEL TO UNITY CATALOG\n",
    "# =============================================================================\n",
    "def register_model(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Register the approved model to Unity Catalog\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 3: Registering Model to Unity Catalog\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Check if model is approved\n",
    "    if not eval_results['should_register']:\n",
    "        print(\"‚ùå Model NOT APPROVED for registration\")\n",
    "        print(f\"   Reason: {eval_results['reason']}\")\n",
    "        print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚è≠Ô∏è Model registration skipped for `{config.MODEL_NAME}`\\n\"\n",
    "            f\"Reason: {eval_results['reason']}\",\n",
    "            level=\"warning\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate = check_duplicate(eval_results)\n",
    "    if duplicate:\n",
    "        return duplicate\n",
    "\n",
    "    # Proceed with registration\n",
    "    try:\n",
    "        print(f\"\\n‚è≥ Registering model...\")\n",
    "        print(f\"   Model URI: {eval_results['model_uri']}\")\n",
    "        print(f\"   Target: {config.MODEL_NAME}\")\n",
    "        \n",
    "        # Register the model\n",
    "        new_version = mlflow.register_model(\n",
    "            eval_results['model_uri'], \n",
    "            config.MODEL_NAME\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "        print(f\"   Version: v{new_version.version}\")\n",
    "        print(f\"   Source Run ID: {eval_results['run_id']}\")\n",
    "        print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "        print(f\"   {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\")\n",
    "        print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Send Slack notification\n",
    "        slack.send(\n",
    "            f\"‚úÖ Model *{config.MODEL_NAME}* registered as version *v{new_version.version}*\\n\"\n",
    "            f\"üìä {config.METRIC_KEY}: {eval_results['metric_value']:.6f}\\n\"\n",
    "            f\"üìà Improvement: {eval_results['improvement_pct']:.2f}%\\n\"\n",
    "            f\"üîó Run: {eval_results['run_name']}\",\n",
    "            level=\"success\"\n",
    "        )\n",
    "        \n",
    "        return new_version\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Registration failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚ùå Model registration failed for `{config.MODEL_NAME}`: {e}\",\n",
    "            level=\"error\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üè∑Ô∏è STEP 4: SET STAGING ALIAS & ADD TAGS\n",
    "# =============================================================================\n",
    "def set_staging_alias_and_tags(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Set Staging alias and add comprehensive tags\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Setting Alias & Tags\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Set Staging alias\n",
    "        print(f\"‚è≥ Setting @{config.STAGING_ALIAS} alias for Version {version_number}\")\n",
    "        \n",
    "        client.set_registered_model_alias(\n",
    "            config.MODEL_NAME, \n",
    "            config.STAGING_ALIAS, \n",
    "            version_number\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Alias Set: Version {version_number} ‚Üí @{config.STAGING_ALIAS}\")\n",
    "        \n",
    "        # Add comprehensive tags\n",
    "        tags = {\n",
    "            \"registered_from\": \"registration_pipeline\",\n",
    "            \"evaluation_reason\": eval_results['reason'],\n",
    "            \"improvement_pct\": f\"{eval_results['improvement_pct']:.2f}\",\n",
    "            \"registration_timestamp\": datetime.now().isoformat(),\n",
    "            \"metric_rmse\": str(eval_results['metric_value']),\n",
    "            \"source_run_id\": eval_results['run_id'],\n",
    "            \"source_run_name\": eval_results['run_name'],\n",
    "            \"total_runs_evaluated\": str(eval_results['total_runs']),\n",
    "            \"artifact_path\": eval_results['artifact_path'],\n",
    "            \"evaluation_timestamp\": str(eval_results['evaluation_time'])\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüè∑Ô∏è  Adding tags to Version {version_number}:\")\n",
    "        for key, value in tags.items():\n",
    "            try:\n",
    "                client.set_model_version_tag(\n",
    "                    config.MODEL_NAME, \n",
    "                    version_number, \n",
    "                    key, \n",
    "                    value\n",
    "                )\n",
    "                print(f\"   ‚úÖ {key}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Failed to add tag {key}: {e}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ All tags added successfully\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to set alias or tags: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìù STEP 5: UPDATE EVALUATION LOG\n",
    "# =============================================================================\n",
    "def update_evaluation_log(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Update evaluation log with registration status\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 5: Updating Evaluation Log\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Read existing log\n",
    "        df = spark.read.format(\"delta\").table(config.EVALUATION_LOG_TABLE)\n",
    "        \n",
    "        if df.count() == 0:\n",
    "            print(\"‚ö†Ô∏è Evaluation log is empty, cannot update\")\n",
    "            return False\n",
    "        \n",
    "        # Convert to pandas for easier manipulation\n",
    "        pdf = df.toPandas()\n",
    "        \n",
    "        # Find the matching row by run_id\n",
    "        mask = pdf['new_run_id'] == eval_results['run_id']\n",
    "        \n",
    "        if mask.any():\n",
    "            pdf.loc[mask, 'promoted_to_staging'] = True\n",
    "            pdf.loc[mask, 'promoted_version'] = int(version_number)\n",
    "            \n",
    "            # Convert back to Spark DataFrame\n",
    "            updated_df = spark.createDataFrame(pdf)\n",
    "            \n",
    "            # Overwrite table\n",
    "            updated_df.write.format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .option(\"overwriteSchema\", \"true\")\\\n",
    "                .saveAsTable(config.EVALUATION_LOG_TABLE)\n",
    "            \n",
    "            print(f\"‚úÖ Evaluation log updated\")\n",
    "            print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "            print(f\"   Marked as promoted to Staging\")\n",
    "            print(f\"   Version: v{version_number}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No matching record found for run_id: {eval_results['run_id']}\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to update evaluation log: {e}\")\n",
    "        print(\"   (Non-critical error - continuing)\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üìä STEP 6: DISPLAY REGISTRATION SUMMARY\n",
    "# =============================================================================\n",
    "def display_summary(eval_results: Dict, version_number: int) -> None:\n",
    "    \"\"\"Display comprehensive registration summary\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ MODEL REGISTRATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìä Source Model:\")\n",
    "    print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "    print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "    print(f\"   RMSE: {eval_results['metric_value']:.6f}\")\n",
    "    print(f\"   Rank: #1 from {eval_results['total_runs']} runs\")\n",
    "    print(f\"   Evaluated At: {eval_results['evaluation_time']}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Registered Model:\")\n",
    "    print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "    print(f\"   Version: v{version_number}\")\n",
    "    print(f\"   Alias: @{config.STAGING_ALIAS}\")\n",
    "    print(f\"   Status: ‚úÖ ACTIVE\")\n",
    "    \n",
    "    print(f\"\\nüìà Performance:\")\n",
    "    print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "    print(f\"   Reason: {eval_results['reason']}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    print(f\"   1. Test model in Staging environment\")\n",
    "    print(f\"   2. Validate performance metrics\")\n",
    "    print(f\"   3. Run A/B tests if applicable\")\n",
    "    print(f\"   4. Promote to @{config.PRODUCTION_ALIAS} if successful\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Model Access:\")\n",
    "    print(f\"   UC Path: {config.MODEL_NAME}\")\n",
    "    print(f\"   Alias: models:/{config.MODEL_NAME}@{config.STAGING_ALIAS}\")\n",
    "    print(f\"   Version: models:/{config.MODEL_NAME}/{version_number}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# üé¨ MAIN EXECUTION\n",
    "# =============================================================================\n",
    "def main():\n",
    "    \"\"\"Main execution flow with comprehensive error handling\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ STARTING MODEL REGISTRATION PIPELINE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Read evaluation results\n",
    "        eval_results = get_evaluation_results()\n",
    "        if not eval_results:\n",
    "            print(\"\\n‚ùå REGISTRATION FAILED - No evaluation results found\")\n",
    "            print(\"\\nüí° Please run model_evaluation_final_fixed.py first\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Check approval status\n",
    "        if not eval_results['should_register']:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(\"‚è≠Ô∏è REGISTRATION SKIPPED\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"   Model was NOT approved during evaluation\")\n",
    "            print(f\"   Reason: {eval_results['reason']}\")\n",
    "            print(f\"   Improvement: {eval_results['improvement_pct']:.2f}%\")\n",
    "            print(f\"\\nüí° Model needs better performance to be registered\")\n",
    "            print(f\"{'='*80}\")\n",
    "            sys.exit(0)  # Exit gracefully, not an error\n",
    "        \n",
    "        # Step 2 & 3: Register model (includes duplicate check)\n",
    "        new_version = register_model(eval_results)\n",
    "        if not new_version:\n",
    "            print(\"\\n‚ùå REGISTRATION FAILED\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Step 4: Set Staging alias and add tags\n",
    "        alias_set = set_staging_alias_and_tags(new_version.version, eval_results)\n",
    "        if not alias_set:\n",
    "            print(\"\\n‚ö†Ô∏è WARNING: Model registered but alias/tags not set properly\")\n",
    "        \n",
    "        # Step 5: Update evaluation log\n",
    "        update_evaluation_log(new_version.version, eval_results)\n",
    "        \n",
    "        # Step 6: Display summary\n",
    "        display_summary(eval_results, new_version.version)\n",
    "        \n",
    "        print(\"‚úÖ Registration pipeline completed successfully!\")\n",
    "        sys.exit(0)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Process interrupted by user\")\n",
    "        slack.send(\n",
    "            f\"‚ö†Ô∏è Model registration interrupted for `{config.MODEL_NAME}`\",\n",
    "            level=\"warning\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå UNEXPECTED ERROR: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚ùå Critical error in model registration: {e}\",\n",
    "            level=\"error\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# ============================ ENTRY POINT ============================ #\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Databricks notebook source\n",
    "# import mlflow\n",
    "# from mlflow.tracking import MlflowClient\n",
    "# import sys\n",
    "# import os\n",
    "# import requests  # ‚úÖ Added for Slack webhook notifications\n",
    "\n",
    "# # ====================== CONFIGURATION ========================= #\n",
    "# try:\n",
    "#     EXPERIMENT_NAME = dbutils.widgets.get(\"experiment_name\")\n",
    "#     print(f\"‚úì Experiment Name from widget: {EXPERIMENT_NAME}\")\n",
    "# except:\n",
    "#     EXPERIMENT_NAME = \"/Shared/House_Price_Prediction_Config_Runs\"\n",
    "#     print(f\"‚Ñπ Using default experiment: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# UC_CATALOG = \"workspace\"\n",
    "# UC_SCHEMA = \"ml\"\n",
    "\n",
    "# # =================== MODEL CONFIG METADATA ==================== #\n",
    "# MODEL_CONFIG = {\n",
    "#     \"xgboost\": {\n",
    "#         \"model_name\": \"house_price_xgboost_uc2\",\n",
    "#         \"artifact_path\": \"xgboost_model\",\n",
    "#         \"param_keys\": [\n",
    "#             \"n_estimators\", \"max_depth\", \"learning_rate\",\n",
    "#             \"subsample\", \"colsample_bytree\"\n",
    "#         ],\n",
    "#         \"metric_key\": \"test_rmse\",\n",
    "#         \"keywords\": [\"xgboost\", \"xgb\", \"house_price\", \"config_runs\"]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # =================== SLACK NOTIFICATION HELPER ==================== #\n",
    "# def send_slack_notification(message):\n",
    "#     \"\"\"\n",
    "#     Send Slack message using webhook URL.\n",
    "#     Set SLACK_WEBHOOK_URL as environment variable or Databricks secret.\n",
    "#     \"\"\"\n",
    "#     webhook_url = os.getenv(\"SLACK_WEBHOOK_URL\")\n",
    "#     if not webhook_url:\n",
    "#         print(\"‚ö†Ô∏è No Slack webhook URL found. Skipping notification.\")\n",
    "#         return\n",
    "\n",
    "#     payload = {\"text\": message}\n",
    "#     try:\n",
    "#         response = requests.post(webhook_url, json=payload)\n",
    "#         if response.status_code == 200:\n",
    "#             print(\"üì¢ Slack notification sent successfully.\")\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è Slack notification failed: {response.status_code}, {response.text}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Slack notification error: {e}\")\n",
    "\n",
    "# # ================== MODEL TYPE DETECTION ====================== #\n",
    "# def detect_model_config(experiment_name: str):\n",
    "#     exp_lower = experiment_name.lower()\n",
    "#     for model_type, cfg in MODEL_CONFIG.items():\n",
    "#         for key in cfg[\"keywords\"]:\n",
    "#             if key in exp_lower:\n",
    "#                 full_uc_name = f\"{UC_CATALOG}.{UC_SCHEMA}.{cfg['model_name']}\"\n",
    "#                 print(f\"‚úì Detected model type: {model_type.upper()}\")\n",
    "#                 print(f\"‚úì UC Model Name: {full_uc_name}\")\n",
    "#                 return (\n",
    "#                     full_uc_name,\n",
    "#                     cfg[\"artifact_path\"],\n",
    "#                     cfg[\"param_keys\"],\n",
    "#                     cfg[\"metric_key\"]\n",
    "#                 )\n",
    "#     raise ValueError(\"‚ùå No matching model config found based on experiment name!\")\n",
    "\n",
    "# REGISTERED_MODEL_NAME, ARTIFACT_PATH, PARAM_KEYS, METRIC_KEY = detect_model_config(EXPERIMENT_NAME)\n",
    "# TOL = 1e-6  # float tolerance\n",
    "\n",
    "# # ====================== UTILITIES ====================== #\n",
    "# def normalize(val):\n",
    "#     try:\n",
    "#         if '.' not in str(val) and str(val).isdigit():\n",
    "#             return int(val)\n",
    "#         return float(val)\n",
    "#     except:\n",
    "#         return str(val)\n",
    "\n",
    "# # ================== FIND BEST RUN ====================== #\n",
    "# def get_best_run(client):\n",
    "#     exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "#     if not exp:\n",
    "#         print(\"‚ùå Experiment not found.\")\n",
    "#         return None, {}, {}\n",
    "\n",
    "#     runs = client.search_runs(\n",
    "#         [exp.experiment_id], \n",
    "#         order_by=[f\"metrics.{METRIC_KEY} ASC\"],\n",
    "#         max_results=1000\n",
    "#     )\n",
    "    \n",
    "#     if not runs:\n",
    "#         print(\"‚ö† No runs found in experiment.\")\n",
    "#         return None, {}, {}\n",
    "\n",
    "#     best_run = None\n",
    "#     best_metric = float(\"inf\")\n",
    "\n",
    "#     for r in runs:\n",
    "#         metric_val = r.data.metrics.get(METRIC_KEY)\n",
    "#         if metric_val is not None:\n",
    "#             print(f\"  üìä Run: {r.info.run_name or r.info.run_id[:8]} | {METRIC_KEY}: {metric_val:.4f}\")\n",
    "#             if metric_val < best_metric:\n",
    "#                 best_metric = metric_val\n",
    "#                 best_run = r\n",
    "\n",
    "#     if best_run:\n",
    "#         params = {k: normalize(v) for k, v in best_run.data.params.items() if k in PARAM_KEYS}\n",
    "#         metrics = best_run.data.metrics\n",
    "        \n",
    "#         print(f\"\\n{'='*70}\")\n",
    "#         print(f\"üèÜ BEST RUN IDENTIFIED:\")\n",
    "#         print(f\"{'='*70}\")\n",
    "#         print(f\"   Run Name: {best_run.info.run_name or 'N/A'}\")\n",
    "#         print(f\"   Run ID: {best_run.info.run_id}\")\n",
    "#         print(f\"   {METRIC_KEY}: {best_metric:.6f}\")\n",
    "#         print(f\"   Parameters: {params}\")\n",
    "#         print(f\"{'='*70}\\n\")\n",
    "        \n",
    "#         return best_run.info.run_id, params, metrics\n",
    "#     else:\n",
    "#         print(\"‚ö† No valid runs with metric found.\")\n",
    "#         return None, {}, {}\n",
    "\n",
    "# # ================ DUPLICATE VERSION CHECK ===================== #\n",
    "# def check_duplicate(client, new_params, new_metrics):\n",
    "#     try:\n",
    "#         mv_list = client.search_model_versions(f\"name = '{REGISTERED_MODEL_NAME}'\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚Ñπ No existing model versions found (this may be first registration): {e}\")\n",
    "#         return None\n",
    "    \n",
    "#     if not mv_list:\n",
    "#         return None\n",
    "\n",
    "#     new_metric_val = new_metrics.get(METRIC_KEY, None)\n",
    "    \n",
    "#     for mv in mv_list:\n",
    "#         try:\n",
    "#             run = client.get_run(mv.run_id)\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö† Could not fetch run {mv.run_id}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         old_params = {k: normalize(v) for k, v in run.data.params.items() if k in new_params}\n",
    "#         old_metric_val = run.data.metrics.get(METRIC_KEY, None)\n",
    "\n",
    "#         same_params = all(old_params.get(k) == new_params.get(k) for k in new_params)\n",
    "#         same_metric = (\n",
    "#             old_metric_val is not None and new_metric_val is not None\n",
    "#             and abs(old_metric_val - new_metric_val) <= TOL\n",
    "#         )\n",
    "        \n",
    "#         if same_params and same_metric:\n",
    "#             print(f\"\\n‚è≠Ô∏è DUPLICATE DETECTED!\")\n",
    "#             print(f\"   Existing Version: {mv.version}\")\n",
    "#             print(f\"   Run ID: {mv.run_id}\")\n",
    "#             print(f\"   This model is already registered with same params & performance.\")\n",
    "#             return mv\n",
    "            \n",
    "#     return None\n",
    "\n",
    "# # ================== REGISTER MODEL LOGIC ======================= #\n",
    "# def register_model(client, run_id, params, metrics):\n",
    "#     duplicate_version = check_duplicate(client, params, metrics)\n",
    "#     if duplicate_version:\n",
    "#         print(f\"‚úÖ Using existing registered version: {duplicate_version.version}\")\n",
    "#         send_slack_notification(f\"‚ö†Ô∏è Duplicate detected ‚Äî using existing model version *v{duplicate_version.version}* for `{REGISTERED_MODEL_NAME}`.\")\n",
    "#         return duplicate_version\n",
    "\n",
    "#     model_uri = f\"runs:/{run_id}/{ARTIFACT_PATH}\"\n",
    "#     print(f\"\\n‚è≥ Registering new model version...\")\n",
    "#     print(f\"   Model URI: {model_uri}\")\n",
    "#     print(f\"   Target: {REGISTERED_MODEL_NAME}\")\n",
    "\n",
    "#     try:\n",
    "#         new_version = mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)\n",
    "        \n",
    "#         print(f\"\\n{'='*70}\")\n",
    "#         print(\"‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "#         print(f\"{'='*70}\")\n",
    "#         print(f\"   Model Name: {REGISTERED_MODEL_NAME}\")\n",
    "#         print(f\"   Version: {new_version.version}\")\n",
    "#         print(f\"   Source Run ID: {run_id}\")\n",
    "#         print(f\"   {METRIC_KEY}: {metrics.get(METRIC_KEY, 'N/A')}\")\n",
    "#         print(f\"{'='*70}\\n\")\n",
    "\n",
    "#         # üè∑Ô∏è Add helpful tags\n",
    "#         client.set_model_version_tag(\n",
    "#             REGISTERED_MODEL_NAME, \n",
    "#             new_version.version, \n",
    "#             \"source_run_id\", \n",
    "#             run_id\n",
    "#         )\n",
    "#         client.set_model_version_tag(\n",
    "#             REGISTERED_MODEL_NAME, \n",
    "#             new_version.version, \n",
    "#             \"experiment_name\", \n",
    "#             EXPERIMENT_NAME\n",
    "#         )\n",
    "#         client.set_model_version_tag(\n",
    "#             REGISTERED_MODEL_NAME, \n",
    "#             new_version.version, \n",
    "#             \"metric_rmse\", \n",
    "#             str(metrics.get(METRIC_KEY, \"\"))\n",
    "#         )\n",
    "        \n",
    "#         for param_key, param_val in params.items():\n",
    "#             client.set_model_version_tag(\n",
    "#                 REGISTERED_MODEL_NAME,\n",
    "#                 new_version.version,\n",
    "#                 f\"param_{param_key}\",\n",
    "#                 str(param_val)\n",
    "#             )\n",
    "\n",
    "#         # ‚úÖ Send Slack success message\n",
    "#         send_slack_notification(\n",
    "#             f\"‚úÖ Model *{REGISTERED_MODEL_NAME}* registered successfully as version *v{new_version.version}*.\\n\"\n",
    "#             f\"üè∑ Metric `{METRIC_KEY}` = {metrics.get(METRIC_KEY, 'N/A')}\\n\"\n",
    "#             f\"üîó Run ID: {run_id}\"\n",
    "#         )\n",
    "\n",
    "#         return new_version\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Registration Failed: {e}\")\n",
    "#         send_slack_notification(f\"‚ùå Model registration failed for `{REGISTERED_MODEL_NAME}` ‚Äî {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         sys.exit(1)\n",
    "\n",
    "# # ============================ MAIN ============================ #\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"\\n\" + \"=\" * 70)\n",
    "#     print(\"üöÄ MODEL REGISTRATION - BEST RUN SELECTION (MLflow + UC)\")\n",
    "#     print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "#     client = MlflowClient()\n",
    "    \n",
    "#     print(f\"üìã Configuration:\")\n",
    "#     print(f\"   Experiment: {EXPERIMENT_NAME}\")\n",
    "#     print(f\"   Target Model: {REGISTERED_MODEL_NAME}\")\n",
    "#     print(f\"   Metric to optimize: {METRIC_KEY} (lower is better)\")\n",
    "#     print(f\"   Artifact Path: {ARTIFACT_PATH}\\n\")\n",
    "    \n",
    "#     print(\"üîç Searching for best run...\")\n",
    "#     run_id, params, metrics = get_best_run(client)\n",
    "\n",
    "#     if run_id:\n",
    "#         register_model(client, run_id, params, metrics)\n",
    "#         print(\"\\n‚ú® Registration process completed successfully!\")\n",
    "#     else:\n",
    "#         print(\"‚ùå No valid best run found. Exiting.\")\n",
    "#         send_slack_notification(f\"‚ö†Ô∏è Model registration skipped ‚Äî no valid best run found for `{REGISTERED_MODEL_NAME}`.\")\n",
    "#         sys.exit(1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
