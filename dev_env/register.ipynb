{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# =============================================================================\n",
    "# üèÜ MODEL REGISTRATION SCRIPT - CONFIG DRIVEN (FIXED)\n",
    "# =============================================================================\n",
    "# Purpose: Register approved models from evaluation pipeline\n",
    "# Now reads from pipeline_config.yml - No hardcoding!\n",
    "# Prerequisites: Run model_evaluation_FIXED.py first\n",
    "# =============================================================================\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "import traceback\n",
    "from typing import Dict, Optional, Any\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from delta.tables import DeltaTable\n",
    "from IPython import get_ipython\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üèÜ MODEL REGISTRATION SYSTEM (CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ LOAD PIPELINE CONFIGURATION\n",
    "# =============================================================================\n",
    "print(\"\\nüìã Loading pipeline configuration from pipeline_config.yml...\")\n",
    "\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Pipeline configuration loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: pipeline_config.yml not found!\")\n",
    "    print(\"üí° Please create pipeline_config.yml in the same directory\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR loading configuration: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ CONFIGURATION CLASS (NOW DYNAMIC!)\n",
    "# =============================================================================\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration management - reads from pipeline_config.yml\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Extract from pipeline config\n",
    "        MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "        UC_CATALOG = pipeline_cfg[\"model\"][\"catalog\"]\n",
    "        UC_SCHEMA = pipeline_cfg[\"model\"][\"schema\"]\n",
    "        BASE_NAME = pipeline_cfg[\"model\"][\"base_name\"]\n",
    "        \n",
    "        # Unity Catalog Configuration (dynamic)\n",
    "        self.UC_CATALOG = UC_CATALOG\n",
    "        self.UC_SCHEMA = UC_SCHEMA\n",
    "        self.MODEL_NAME = f\"{UC_CATALOG}.{UC_SCHEMA}.{BASE_NAME}_{MODEL_TYPE}_uc2\"\n",
    "        \n",
    "        # Aliases\n",
    "        self.STAGING_ALIAS = pipeline_cfg[\"aliases\"][\"staging\"]\n",
    "        self.PRODUCTION_ALIAS = pipeline_cfg[\"aliases\"][\"production\"]\n",
    "        \n",
    "        # Delta Tables\n",
    "        self.BEST_MODEL_METADATA_TABLE = pipeline_cfg[\"tables\"][\"best_model_metadata\"]\n",
    "        self.EVALUATION_LOG_TABLE = pipeline_cfg[\"tables\"][\"evaluation_log\"]\n",
    "        \n",
    "        # Model Configuration\n",
    "        self.ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "        self.METRIC_KEY = pipeline_cfg[\"metrics\"][\"primary_metric\"]\n",
    "        self.TOL = 1e-6\n",
    "        \n",
    "        # Slack Configuration\n",
    "        self.SLACK_WEBHOOK_URL = self._get_slack_webhook()\n",
    "        \n",
    "        # Store model type for reference\n",
    "        self.MODEL_TYPE = MODEL_TYPE\n",
    "        \n",
    "    def _get_slack_webhook(self) -> Optional[str]:\n",
    "        \"\"\"Safely retrieve Slack webhook URL\"\"\"\n",
    "        scopes = [\"shared-scope\", \"dev-scope\"]\n",
    "        for scope in scopes:\n",
    "            try:\n",
    "                webhook = dbutils.secrets.get(scope, \"SLACK_WEBHOOK_URL\")\n",
    "                if webhook and webhook.strip():\n",
    "                    print(f\"‚úÖ Slack webhook configured from scope '{scope}'\")\n",
    "                    return webhook\n",
    "            except Exception:\n",
    "                continue\n",
    "        print(\"‚ÑπÔ∏è Slack notifications disabled\")\n",
    "        return None\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(f\"\\nüìä Configuration Details:\")\n",
    "print(f\"   Model Type: {config.MODEL_TYPE.upper()}\")\n",
    "print(f\"   Model Name: {config.MODEL_NAME}\")\n",
    "print(f\"   Staging Alias: @{config.STAGING_ALIAS}\")\n",
    "print(f\"   Production Alias: @{config.PRODUCTION_ALIAS}\")\n",
    "print(f\"   Metadata Table: {config.BEST_MODEL_METADATA_TABLE}\")\n",
    "print(f\"   Log Table: {config.EVALUATION_LOG_TABLE}\")\n",
    "print(f\"   Metric: {config.METRIC_KEY}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ SLACK NOTIFICATION HELPER\n",
    "# =============================================================================\n",
    "class SlackNotifier:\n",
    "    \"\"\"Enhanced Slack notification handler\"\"\"\n",
    "    \n",
    "    def __init__(self, webhook_url: Optional[str]):\n",
    "        self.webhook_url = webhook_url\n",
    "        self.enabled = webhook_url is not None\n",
    "        \n",
    "    def send(self, message: str, level: str = \"info\") -> bool:\n",
    "        \"\"\"Send Slack notification with error handling\"\"\"\n",
    "        if not self.enabled:\n",
    "            print(f\"üì¢ [SLACK DISABLED] {message}\")\n",
    "            return False\n",
    "            \n",
    "        emoji_map = {\n",
    "            \"info\": \"‚ÑπÔ∏è\",\n",
    "            \"success\": \"‚úÖ\",\n",
    "            \"warning\": \"‚ö†Ô∏è\",\n",
    "            \"error\": \"‚ùå\"\n",
    "        }\n",
    "        \n",
    "        formatted_message = f\"{emoji_map.get(level, '‚ÑπÔ∏è')} {message}\"\n",
    "        payload = {\"text\": formatted_message}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.webhook_url, \n",
    "                json=payload,\n",
    "                timeout=5\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                print(f\"üì¢ Slack notification sent: {level}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Slack error: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Slack notification failed: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize Slack notifier\n",
    "slack = SlackNotifier(config.SLACK_WEBHOOK_URL)\n",
    "\n",
    "# =============================================================================\n",
    "# ‚úÖ INITIALIZATION\n",
    "# =============================================================================\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"ModelRegistration\").getOrCreate()\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = MlflowClient()\n",
    "    print(\"\\n‚úÖ MLflow and Spark initialized\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Initialization failed: {e}\")\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)\n",
    "\n",
    "# =============================================================================\n",
    "# üîß HELPER: GET MODEL ALIASES SAFELY\n",
    "# =============================================================================\n",
    "def get_model_aliases_safe(model_name: str, version: int) -> list:\n",
    "    \"\"\"Safely get aliases for a model version\"\"\"\n",
    "    try:\n",
    "        common_aliases = ['production', 'Staging', 'champion', 'baseline']\n",
    "        found_aliases = []\n",
    "        for alias in common_aliases:\n",
    "            try:\n",
    "                alias_version = client.get_model_version_by_alias(model_name, alias)\n",
    "                if alias_version and str(alias_version.version) == str(version):\n",
    "                    found_aliases.append(alias)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return found_aliases\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# =============================================================================\n",
    "# üìã STEP 1: READ EVALUATION RESULTS\n",
    "# =============================================================================\n",
    "def get_evaluation_results() -> Optional[Dict]:\n",
    "    \"\"\"Read latest evaluation results from Delta table\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 1: Reading Evaluation Results\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # Check if table exists\n",
    "        tables = spark.catalog.listTables(\"default\")\n",
    "        table_names = [t.name for t in tables]\n",
    "        \n",
    "        if \"best_model_metadata\" not in table_names:\n",
    "            print(f\"‚ùå Table '{config.BEST_MODEL_METADATA_TABLE}' not found!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_FIXED.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Read latest evaluation\n",
    "        df = spark.read.format(\"delta\").table(config.BEST_MODEL_METADATA_TABLE)\n",
    "        \n",
    "        if df.count() == 0:\n",
    "            print(\"‚ùå No evaluation results found in table!\")\n",
    "            print(\"\\nüí° Please run model_evaluation_FIXED.py first\")\n",
    "            return None\n",
    "        \n",
    "        # Get latest evaluation (most recent timestamp)\n",
    "        latest = df.orderBy(df.evaluation_timestamp.desc()).first()\n",
    "        \n",
    "        print(f\"‚úÖ Evaluation Results Found:\")\n",
    "        print(f\"   Evaluated At: {latest.evaluation_timestamp}\")\n",
    "        print(f\"   Model Type: {config.MODEL_TYPE.upper()}\")\n",
    "        print(f\"   Target Registry: {config.MODEL_NAME}\")\n",
    "        print(f\"   Run ID: {latest.run_id}\")\n",
    "        print(f\"   Run Name: {latest.run_name}\")\n",
    "        print(f\"   Model URI: {latest.model_uri}\")\n",
    "        print(f\"   Metric ({latest.metric_key}): {latest.metric_value:.6f}\")\n",
    "        print(f\"   Should Register: {'YES ‚úÖ' if latest.should_register else 'NO ‚ùå'}\")\n",
    "        print(f\"   Reason: {latest.evaluation_reason}\")\n",
    "        print(f\"   Improvement: {latest.improvement_pct:.2f}%\")\n",
    "        print(f\"   Total Runs Evaluated: {latest.total_runs_evaluated}\")\n",
    "        \n",
    "        return {\n",
    "            'run_id': latest.run_id,\n",
    "            'run_name': latest.run_name,\n",
    "            'model_uri': latest.model_uri,\n",
    "            'artifact_path': latest.artifact_path,\n",
    "            'metric_key': latest.metric_key,\n",
    "            'metric_value': float(latest.metric_value),\n",
    "            'should_register': bool(latest.should_register),\n",
    "            'reason': latest.evaluation_reason,\n",
    "            'improvement_pct': float(latest.improvement_pct),\n",
    "            'total_runs': int(latest.total_runs_evaluated),\n",
    "            'evaluation_time': latest.evaluation_timestamp,\n",
    "            'params_json': latest.params_json if hasattr(latest, 'params_json') else \"{}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read evaluation results: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# üîç STEP 2: CHECK FOR DUPLICATE VERSIONS\n",
    "# =============================================================================\n",
    "def check_duplicate(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Check if model with same run_id already exists\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 2: Checking for Duplicates\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        mv_list = client.search_model_versions(f\"name = '{config.MODEL_NAME}'\")\n",
    "        versions_list = list(mv_list)\n",
    "        \n",
    "    except Exception:\n",
    "        print(f\"‚ÑπÔ∏è No existing model versions (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    if not versions_list:\n",
    "        print(\"‚ÑπÔ∏è No existing versions found (first registration)\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(versions_list)} existing version(s)\")\n",
    "    \n",
    "    new_run_id = eval_results['run_id']\n",
    "    new_metric = eval_results['metric_value']\n",
    "    \n",
    "    for mv in versions_list:\n",
    "        try:\n",
    "            if mv.run_id == new_run_id:\n",
    "                version_aliases = get_model_aliases_safe(config.MODEL_NAME, mv.version)\n",
    "                aliases_str = ', '.join(version_aliases) if version_aliases else 'None'\n",
    "                \n",
    "                print(f\"\\n‚ö†Ô∏è DUPLICATE DETECTED!\")\n",
    "                print(f\"   Existing Version: v{mv.version}\")\n",
    "                print(f\"   Run ID: {mv.run_id}\")\n",
    "                print(f\"   Aliases: {aliases_str}\")\n",
    "                print(f\"\\n   ‚Üí Model already registered, skipping registration\")\n",
    "                \n",
    "                slack.send(\n",
    "                    f\"‚ö†Ô∏è Duplicate detected ‚Äî using existing version *v{mv.version}* \"\n",
    "                    f\"for `{config.MODEL_NAME}`\",\n",
    "                    level=\"warning\"\n",
    "                )\n",
    "                return mv\n",
    "            \n",
    "            try:\n",
    "                run = client.get_run(mv.run_id)\n",
    "                old_metric = run.data.metrics.get(config.METRIC_KEY)\n",
    "                \n",
    "                if old_metric and abs(old_metric - new_metric) <= config.TOL:\n",
    "                    print(f\"\\n‚ö†Ô∏è Similar model found!\")\n",
    "                    print(f\"   Version: v{mv.version}\")\n",
    "                    print(f\"   Metric difference: {abs(old_metric - new_metric):.8f}\")\n",
    "                    print(f\"   (Within tolerance: {config.TOL})\")\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error checking version {mv.version}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n‚úÖ No duplicates found - proceeding with registration\")\n",
    "    return None\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ STEP 3: REGISTER MODEL TO UNITY CATALOG\n",
    "# =============================================================================\n",
    "def register_model(eval_results: Dict) -> Optional[Any]:\n",
    "    \"\"\"Register the approved model to Unity Catalog\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 3: Registering Model to Unity Catalog\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    if not eval_results['should_register']:\n",
    "        print(\"‚ùå Model NOT APPROVED for registration\")\n",
    "        slack.send(\n",
    "            f\"‚è≠Ô∏è Model registration skipped for `{config.MODEL_NAME}`\\n\"\n",
    "            f\"Reason: {eval_results['reason']}\",\n",
    "            level=\"warning\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    duplicate = check_duplicate(eval_results)\n",
    "    if duplicate:\n",
    "        return duplicate\n",
    "\n",
    "    try:\n",
    "        print(f\"\\n‚è≥ Registering model to: {config.MODEL_NAME}\")\n",
    "        print(f\"   Model URI: {eval_results['model_uri']}\")\n",
    "        \n",
    "        new_version = mlflow.register_model(eval_results['model_uri'], config.MODEL_NAME)\n",
    "        \n",
    "        print(f\"\\n‚úÖ MODEL REGISTERED SUCCESSFULLY!\")\n",
    "        print(f\"   Model: {config.MODEL_NAME}\")\n",
    "        print(f\"   Version: v{new_version.version}\")\n",
    "        print(f\"   Model Type: {config.MODEL_TYPE.upper()}\")\n",
    "        \n",
    "        slack.send(\n",
    "            f\"‚úÖ Model *{config.MODEL_NAME}* registered as version *v{new_version.version}*\\n\"\n",
    "            f\"Model Type: {config.MODEL_TYPE.upper()}\",\n",
    "            level=\"success\"\n",
    "        )\n",
    "        return new_version\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Registration failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        slack.send(\n",
    "            f\"‚ùå Model registration failed for `{config.MODEL_NAME}`: {e}\",\n",
    "            level=\"error\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# üè∑Ô∏è STEP 4: SET STAGING ALIAS & ADD TAGS\n",
    "# =============================================================================\n",
    "def set_staging_alias_and_tags(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Set staging alias and add metadata tags\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 4: Setting Staging Alias and Tags\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        # Set staging alias\n",
    "        print(f\"   Setting @{config.STAGING_ALIAS} alias...\")\n",
    "        client.set_registered_model_alias(\n",
    "            config.MODEL_NAME, \n",
    "            config.STAGING_ALIAS, \n",
    "            version_number\n",
    "        )\n",
    "        print(f\"   ‚úì Alias set: @{config.STAGING_ALIAS}\")\n",
    "        \n",
    "        # Add tags\n",
    "        print(f\"   Adding metadata tags...\")\n",
    "        tags = {\n",
    "            \"model_type\": config.MODEL_TYPE,\n",
    "            \"registered_from\": \"registration_pipeline\",\n",
    "            \"evaluation_reason\": eval_results['reason'],\n",
    "            \"improvement_pct\": f\"{eval_results['improvement_pct']:.2f}\",\n",
    "            \"registration_timestamp\": datetime.now().isoformat(),\n",
    "            \"metric_rmse\": str(eval_results['metric_value']),\n",
    "            \"source_run_id\": eval_results['run_id'],\n",
    "            \"source_run_name\": eval_results['run_name'],\n",
    "            \"total_runs_evaluated\": str(eval_results['total_runs']),\n",
    "            \"artifact_path\": eval_results['artifact_path'],\n",
    "            \"evaluation_timestamp\": str(eval_results['evaluation_time'])\n",
    "        }\n",
    "        \n",
    "        for key, value in tags.items():\n",
    "            try:\n",
    "                client.set_model_version_tag(config.MODEL_NAME, version_number, key, value)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Failed to set tag '{key}': {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"   ‚úì Tags added successfully\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to set alias/tags: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# üìù STEP 5: UPDATE EVALUATION LOG\n",
    "# =============================================================================\n",
    "def update_evaluation_log(version_number: int, eval_results: Dict) -> bool:\n",
    "    \"\"\"Update evaluation log with registration info\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üìã STEP 5: Updating Evaluation Log\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        delta_table = DeltaTable.forName(spark, config.EVALUATION_LOG_TABLE)\n",
    "        delta_table.update(\n",
    "            condition=f\"new_run_id = '{eval_results['run_id']}'\",\n",
    "            set={\n",
    "                \"promoted_to_staging\": True,\n",
    "                \"promoted_version\": version_number\n",
    "            }\n",
    "        )\n",
    "        print(f\"‚úÖ Evaluation log updated\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to update log: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# üìä STEP 6: DISPLAY REGISTRATION SUMMARY\n",
    "# =============================================================================\n",
    "def display_summary(eval_results: Dict, version_number: int) -> None:\n",
    "    \"\"\"Display registration summary\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ‚úÖ MODEL REGISTRATION COMPLETE ‚úÖ‚úÖ\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nüìä Source Model:\")\n",
    "    print(f\"   Model Type: {config.MODEL_TYPE.upper()}\")\n",
    "    print(f\"   Run ID: {eval_results['run_id']}\")\n",
    "    print(f\"   Run Name: {eval_results['run_name']}\")\n",
    "    print(f\"   {config.METRIC_KEY.upper()}: {eval_results['metric_value']:.6f}\")\n",
    "    print(f\"\\nüèÜ Registered Model:\")\n",
    "    print(f\"   Registry: {config.MODEL_NAME}\")\n",
    "    print(f\"   Version: v{version_number}\")\n",
    "    print(f\"   Alias: @{config.STAGING_ALIAS}\")\n",
    "    print(f\"\\nüìå Next Steps:\")\n",
    "    print(f\"   1. Run UAT Staging Promotion\")\n",
    "    print(f\"   2. Run UAT Inference\")\n",
    "    print(f\"   3. If UAT passes ‚Üí Production Promotion\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# üé¨ MAIN EXECUTION\n",
    "# =============================================================================\n",
    "def exit_notebook_friendly(code=0):\n",
    "    \"\"\"Exit safely in notebooks, sys.exit in scripts\"\"\"\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        return\n",
    "    else:\n",
    "        sys.exit(code)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main registration pipeline\"\"\"\n",
    "    try:\n",
    "        # Step 1: Read evaluation results\n",
    "        eval_results = get_evaluation_results()\n",
    "        if not eval_results:\n",
    "            print(\"\\n‚ùå No evaluation results found\")\n",
    "            exit_notebook_friendly(1)\n",
    "        \n",
    "        # Step 2: Check if approved\n",
    "        if not eval_results['should_register']:\n",
    "            print(\"\\n‚è≠Ô∏è REGISTRATION SKIPPED (model not approved)\")\n",
    "            print(f\"   Reason: {eval_results['reason']}\")\n",
    "            exit_notebook_friendly(0)\n",
    "        \n",
    "        # Step 3: Register model\n",
    "        new_version = register_model(eval_results)\n",
    "        if not new_version:\n",
    "            print(\"\\n‚ùå Registration failed\")\n",
    "            exit_notebook_friendly(1)\n",
    "        \n",
    "        # Step 4: Set alias and tags\n",
    "        set_staging_alias_and_tags(new_version.version, eval_results)\n",
    "        \n",
    "        # Step 5: Update logs\n",
    "        update_evaluation_log(new_version.version, eval_results)\n",
    "        \n",
    "        # Step 6: Display summary\n",
    "        display_summary(eval_results, new_version.version)\n",
    "        \n",
    "        # Save for workflow\n",
    "        try:\n",
    "            dbutils.jobs.taskValues.set(key=\"model_type\", value=config.MODEL_TYPE)\n",
    "            dbutils.jobs.taskValues.set(key=\"model_name\", value=config.MODEL_NAME)\n",
    "            dbutils.jobs.taskValues.set(key=\"model_version\", value=new_version.version)\n",
    "            print(\"‚úÖ Task values saved for workflow\")\n",
    "        except:\n",
    "            print(\"‚ÑπÔ∏è Not running in workflow - skipping task values\")\n",
    "        \n",
    "        exit_notebook_friendly(0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Registration pipeline failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit_notebook_friendly(1)\n",
    "\n",
    "# Execute\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
