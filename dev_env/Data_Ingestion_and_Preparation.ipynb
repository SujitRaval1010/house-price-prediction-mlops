{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34641b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle # DataFrames ko serialize karne ke liye\n",
    "\n",
    "# Configuration\n",
    "MLFLOW_EXPERIMENT_PATH = \"/Shared/mlops_house_price_prediction_experiment\"\n",
    "DELTA_TABLE_NAME = \"workspace.default.house_price_delta\"\n",
    "DATA_ARTIFACT_PATH = \"prepared_data\"\n",
    "\n",
    "def setup_mlflow():\n",
    "    \"\"\"MLflow tracking aur registry URIs ko set karta hai.\"\"\"\n",
    "    if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "        mlflow.set_tracking_uri(\"databricks\")\n",
    "        # Unity Catalog use kar rahe hain\n",
    "        mlflow.set_registry_uri(\"databricks-uc\") \n",
    "        print(\"‚úÖ MLflow set up for Databricks Unity Catalog.\")\n",
    "    try:\n",
    "        mlflow.set_experiment(MLFLOW_EXPERIMENT_PATH)\n",
    "        print(f\"‚úÖ Experiment set to: {MLFLOW_EXPERIMENT_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not set experiment path. Falling back to default: {e}\")\n",
    "        mlflow.set_experiment(\"mlops_house_price_prediction_experiment\")\n",
    "\n",
    "def run_data_preparation():\n",
    "    \"\"\"Data load, preprocess aur artifacts ko log karta hai.\"\"\"\n",
    "    setup_mlflow()\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"DataPreparation\").getOrCreate()\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"01_Data_Prep\") as run:\n",
    "        print(f\"üöÄ MLflow Data Preparation run started: {run.info.run_id}\")\n",
    "        \n",
    "        # 1. Data Load\n",
    "        try:\n",
    "            df = spark.read.format(\"delta\").table(DELTA_TABLE_NAME).toPandas()\n",
    "            print(f\"‚úÖ Data loaded from {DELTA_TABLE_NAME}. Shape: {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading Delta table: {e}\")\n",
    "            raise\n",
    "\n",
    "        # 2. Features and target\n",
    "        X = df[[\"sq_feet\", \"num_bedrooms\", \"num_bathrooms\", \"year_built\", \"location_score\"]]\n",
    "        y = df[\"price\"]\n",
    "\n",
    "        # 3. Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # 4. Save DataFrames as Artifacts\n",
    "        data_to_save = {\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test\n",
    "        }\n",
    "        \n",
    "        # DataFrames ko pickle karke temporary file mein save karte hain\n",
    "        for name, data in data_to_save.items():\n",
    "            temp_file = f\"{name}.pkl\"\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            \n",
    "            # MLflow mein artifact ke roop mein log karte hain\n",
    "            mlflow.log_artifact(temp_file, DATA_ARTIFACT_PATH)\n",
    "            os.remove(temp_file) # Temporary file ko delete kar dete hain\n",
    "            print(f\"üì¶ Logged {name} to MLflow artifact path: {DATA_ARTIFACT_PATH}/{name}.pkl\")\n",
    "\n",
    "        print(f\"\\n--- Data Preparation Complete ---\")\n",
    "        print(f\"Data Prep Run ID: {run.info.run_id}\")\n",
    "        \n",
    "        # Yeh run ID agle step ke liye zaroori hai\n",
    "        return run.info.run_id \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prep_run_id = run_data_preparation()\n",
    "    # Databricks Job mein, yeh ID agle job parameter mein pass kiya jayega\n",
    "    print(f\"üí° The Data Preparation Run ID for next step is: {prep_run_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
