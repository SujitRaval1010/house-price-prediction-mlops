{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# ==================================================================================\n",
    "# üöÄ TRAINING SCRIPT - CONFIG DRIVEN (FIXED VERSION)\n",
    "# ==================================================================================\n",
    "# Now reads from pipeline_config.yml - No hardcoding!\n",
    "# Your config.yml remains unchanged - only experiment parameters\n",
    "# ==================================================================================\n",
    "\n",
    "%pip install xgboost\n",
    "\n",
    "import mlflow\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ TRAINING PIPELINE STARTED (CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ==================================================================================\n",
    "# ‚úÖ LOAD PIPELINE CONFIGURATION (NEW - REPLACES HARDCODING)\n",
    "# ==================================================================================\n",
    "print(\"\\nüìã Loading pipeline configuration from pipeline_config.yml...\")\n",
    "\n",
    "try:\n",
    "    with open(\"pipeline_config.yml\", \"r\") as f:\n",
    "        pipeline_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract configuration values\n",
    "    MODEL_TYPE = pipeline_cfg[\"model\"][\"type\"]\n",
    "    EXPERIMENT_NAME = pipeline_cfg[\"experiment\"][\"name\"]\n",
    "    MODEL_ARTIFACT_PATH = pipeline_cfg[\"experiment\"][\"artifact_path\"]\n",
    "    \n",
    "    FEATURE_COLS = pipeline_cfg[\"data\"][\"features\"]\n",
    "    LABEL_COL = pipeline_cfg[\"data\"][\"label\"]\n",
    "    \n",
    "    # Extract just table name (handle both formats)\n",
    "    input_table = pipeline_cfg[\"data\"][\"input_table\"]\n",
    "    if \".\" in input_table:\n",
    "        DELTA_TABLE_NAME = input_table.split(\".\")[-1]  # Extract last part\n",
    "    else:\n",
    "        DELTA_TABLE_NAME = input_table\n",
    "    \n",
    "    TEST_SIZE = pipeline_cfg[\"data\"][\"test_size\"]\n",
    "    RANDOM_STATE = pipeline_cfg[\"data\"][\"random_state\"]\n",
    "    \n",
    "    print(f\"‚úÖ Pipeline configuration loaded successfully!\")\n",
    "    print(f\"\\nüìä Configuration Details:\")\n",
    "    print(f\"   Model Type: {MODEL_TYPE.upper()}\")\n",
    "    print(f\"   Experiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"   Artifact Path: {MODEL_ARTIFACT_PATH}\")\n",
    "    print(f\"   Delta Table: {DELTA_TABLE_NAME}\")\n",
    "    print(f\"   Features: {FEATURE_COLS}\")\n",
    "    print(f\"   Label: {LABEL_COL}\")\n",
    "    print(f\"   Test Size: {TEST_SIZE}\")\n",
    "    print(f\"   Random State: {RANDOM_STATE}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: pipeline_config.yml not found!\")\n",
    "    print(\"üí° Please create pipeline_config.yml in the same directory\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR loading configuration: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ==================================================================================\n",
    "# ‚úÖ LOAD EXPERIMENT CONFIGURATIONS (YOUR EXISTING config.yml - NO CHANGE!)\n",
    "# ==================================================================================\n",
    "def load_config(path=\"config.yml\"):\n",
    "    \"\"\"Load experiment hyperparameter configurations\"\"\"\n",
    "    print(f\"\\nüìÑ Loading experiment configurations from: {path}\")\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        num_experiments = len(config[\"experiments\"])\n",
    "        print(f\"‚úÖ Found {num_experiments} experiment configuration(s):\")\n",
    "        \n",
    "        for i, exp in enumerate(config[\"experiments\"], 1):\n",
    "            print(f\"   {i}. {exp['name']}\")\n",
    "        \n",
    "        return config\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: {path} not found!\")\n",
    "        print(\"üí° Please create config.yml with experiment configurations\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR loading experiments: {e}\")\n",
    "        raise\n",
    "\n",
    "# ==================================================================================\n",
    "# ‚úÖ READ DATA FROM DELTA\n",
    "# ==================================================================================\n",
    "def load_data(spark):\n",
    "    \"\"\"Load training data from Delta table\"\"\"\n",
    "    print(f\"\\nüì¶ Loading data from Delta table: {DELTA_TABLE_NAME}\")\n",
    "    \n",
    "    try:\n",
    "        df = spark.read.format(\"delta\").table(DELTA_TABLE_NAME)\n",
    "        df_pd = df.select(*FEATURE_COLS, LABEL_COL).toPandas()\n",
    "        \n",
    "        X = df_pd[FEATURE_COLS]\n",
    "        y = df_pd[LABEL_COL]\n",
    "        \n",
    "        print(f\"‚úÖ Data loaded successfully!\")\n",
    "        print(f\"   Total rows: {len(df_pd):,}\")\n",
    "        print(f\"   Features shape: {X.shape}\")\n",
    "        print(f\"   Label shape: {y.shape}\")\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load data from table '{DELTA_TABLE_NAME}': {e}\")\n",
    "        print(f\"üí° Make sure the Delta table exists and contains required columns\")\n",
    "        raise\n",
    "\n",
    "# ==================================================================================\n",
    "# ‚úÖ TRAIN ONE EXPERIMENT RUN\n",
    "# ==================================================================================\n",
    "def train_single_run(X, y, params, run_name):\n",
    "    \"\"\"\n",
    "    Train a single model configuration\n",
    "    \n",
    "    Args:\n",
    "        X: Feature data\n",
    "        y: Target data  \n",
    "        params: Model hyperparameters from config.yml\n",
    "        run_name: Name for this MLflow run\n",
    "        \n",
    "    Returns:\n",
    "        run_id: MLflow run ID\n",
    "        rmse: Test RMSE score\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üîÅ Training: {run_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    print(f\"   Train size: {len(X_train):,} samples\")\n",
    "    print(f\"   Test size: {len(X_test):,} samples\")\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        print(f\"   MLflow Run ID: {run_id}\")\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", MODEL_TYPE)\n",
    "        for k, v in params.items():\n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        # Train model\n",
    "        print(f\"   üèãÔ∏è Training {MODEL_TYPE.upper()} model...\")\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"   ‚úì Training complete\")\n",
    "\n",
    "        # Evaluate\n",
    "        print(f\"   üìä Evaluating on test set...\")\n",
    "        preds = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "        mlflow.log_metric(\"test_rmse\", rmse)\n",
    "        print(f\"   ‚úÖ Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "        # Signature\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "        # Log the model (artifact_path from pipeline_config.yml)\n",
    "        print(f\"   üíæ Logging model to artifact path: {MODEL_ARTIFACT_PATH}\")\n",
    "        mlflow.xgboost.log_model(\n",
    "            model, \n",
    "            artifact_path=MODEL_ARTIFACT_PATH,\n",
    "            signature=signature\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Run '{run_name}' completed successfully!\")\n",
    "\n",
    "        return run_id, rmse\n",
    "\n",
    "# ==================================================================================\n",
    "# ‚úÖ MAIN EXECUTION\n",
    "# ==================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\nüîß Step 1: Initializing MLflow...\")\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(\"databricks\")\n",
    "        mlflow.set_registry_uri(\"databricks-uc\")\n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"‚úÖ MLflow experiment set: {EXPERIMENT_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize MLflow: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(\"\\nüîß Step 2: Initializing Spark...\")\n",
    "    try:\n",
    "        spark = SparkSession.builder.appName(\"ConfigDrivenTraining\").getOrCreate()\n",
    "        print(\"‚úÖ Spark session created\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize Spark: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(\"\\nüîß Step 3: Loading training data...\")\n",
    "    X, y = load_data(spark)\n",
    "\n",
    "    print(\"\\nüîß Step 4: Loading experiment configurations...\")\n",
    "    config = load_config()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üöÄ STARTING TRAINING RUNS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Store results\n",
    "    run_results = []\n",
    "\n",
    "    # Train all experiments\n",
    "    for idx, exp in enumerate(config[\"experiments\"], 1):\n",
    "        name = exp[\"name\"]\n",
    "        params = exp[\"params\"]\n",
    "        \n",
    "        print(f\"\\n[{idx}/{len(config['experiments'])}] Running experiment: {name}\")\n",
    "        \n",
    "        try:\n",
    "            run_id, rmse = train_single_run(X, y, params, run_name=name)\n",
    "            run_results.append({\n",
    "                'name': name,\n",
    "                'run_id': run_id,\n",
    "                'rmse': rmse,\n",
    "                'params': params\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to train {name}: {e}\")\n",
    "            print(f\"   Continuing with next experiment...\")\n",
    "            continue\n",
    "\n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ‚úÖ‚úÖ ALL TRAINING RUNS COMPLETED ‚úÖ‚úÖ‚úÖ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if run_results:\n",
    "        print(f\"\\nüìä Training Results Summary ({len(run_results)} successful runs):\")\n",
    "        print(f\"{'Rank':<6} {'Experiment Name':<40} {'RMSE':<15} {'Run ID':<40}\")\n",
    "        print(\"-\" * 101)\n",
    "        \n",
    "        # Sort by RMSE (best first)\n",
    "        sorted_results = sorted(run_results, key=lambda x: x['rmse'])\n",
    "        \n",
    "        for rank, result in enumerate(sorted_results, 1):\n",
    "            marker = \"üèÜ\" if rank == 1 else f\"{rank}.\"\n",
    "            name = result['name']\n",
    "            rmse = result['rmse']\n",
    "            run_id = result['run_id']\n",
    "            \n",
    "            print(f\"{marker:<6} {name:<40} {rmse:<15.4f} {run_id}\")\n",
    "        \n",
    "        # Highlight best model\n",
    "        best = sorted_results[0]\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üèÜ BEST MODEL FROM THIS TRAINING SESSION\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"   Name: {best['name']}\")\n",
    "        print(f\"   RMSE: {best['rmse']:.4f}\")\n",
    "        print(f\"   Run ID: {best['run_id']}\")\n",
    "        print(f\"   Parameters:\")\n",
    "        for k, v in best['params'].items():\n",
    "            print(f\"      {k}: {v}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No successful training runs completed\")\n",
    "        print(\"üí° Check errors above and fix configuration\")\n",
    "\n",
    "    print(\"\\nüìå Next Steps:\")\n",
    "    print(\"   1. Run model_evaluation_final_fixed.py to evaluate ALL models in experiment\")\n",
    "    print(\"   2. Best model will be automatically selected by metrics\")\n",
    "    print(\"   3. If approved, it will be registered to Unity Catalog\")\n",
    "    print(\"   4. Then UAT ‚Üí Production pipeline will execute\")\n",
    "    \n",
    "    print(\"\\nüí° Note:\")\n",
    "    print(f\"   All {len(run_results)} models are now logged to experiment: {EXPERIMENT_NAME}\")\n",
    "    print(\"   Evaluation script will compare ALL models (including previous runs)\")\n",
    "    print(\"   and select the absolute best one based on test_rmse\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    # Save metadata for workflow (optional)\n",
    "    try:\n",
    "        dbutils.jobs.taskValues.set(key=\"model_type\", value=MODEL_TYPE)\n",
    "        dbutils.jobs.taskValues.set(key=\"experiment_name\", value=EXPERIMENT_NAME)\n",
    "        dbutils.jobs.taskValues.set(key=\"num_experiments\", value=len(run_results))\n",
    "        if run_results:\n",
    "            dbutils.jobs.taskValues.set(key=\"best_rmse\", value=sorted_results[0]['rmse'])\n",
    "        print(\"‚úÖ Task values saved for workflow\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è Not running in Databricks workflow - skipping task values\")\n",
    "    \n",
    "    print(\"\\nüéâ Training pipeline completed successfully!\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
